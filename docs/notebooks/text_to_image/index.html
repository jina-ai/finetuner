<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<meta property="og:title" content="Text-to-Image Search via CLIP" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://finetuner.jina.ai/notebooks/text_to_image/" />
<meta property="og:site_name" content="Finetuner Documentation" />
<meta property="og:description" content="Traditionally, searching images from text (text-image-retrieval) relies heavily on human annotations, this is commonly referred to as Text/Tag-based Image Retrieval (TBIR). The OpenAI CLIP model maps the dense vectors extracted from text and image into the same semantic space and produces a stron..." />
<meta property="og:image" content="https://user-images.githubusercontent.com/6599259/212634395-6f336d39-cda7-425d-80a2-10facae3b824.png" />
<meta property="og:image:alt" content="clip-example-pt" />
<meta name="description" content="Traditionally, searching images from text (text-image-retrieval) relies heavily on human annotations, this is commonly referred to as Text/Tag-based Image Retrieval (TBIR). The OpenAI CLIP model maps the dense vectors extracted from text and image into the same semantic space and produces a stron..." />
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@JinaAI_">
<meta name="twitter:creator" content="@JinaAI_">
<meta name="description" content="Finetuner is a library for tune the weights of any deep neural network for better embeddings on search tasks.">
<meta property="og:description" content="Finetuner allows one to tune the weights of any deep neural network for better embeddings on search tasks. It accompanies Jina to deliver the last mile of performance for domain-specific neural search applications.">

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1ESRNDCK35"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1ESRNDCK35');
</script>

<script async defer src="https://buttons.github.io/buttons.js"></script>
    
<link rel="index" title="Index" href="../../genindex/" /><link rel="search" title="Search" href="../../search/" /><link rel="next" title="Multilingual Text-to-Image Search with MultilingualCLIP" href="../multilingual_text_to_image/" /><link rel="prev" title="Image-to-Image Search via ResNet50" href="../image_to_image/" />
        <link rel="canonical" href="https://finetuner.jina.ai/notebooks/text_to_image.html" />

    <link rel="shortcut icon" href="../../_static/favicon.png"/><!-- Generated with Sphinx 6.1.3 and Furo 2022.12.07 -->
        <title>Text-to-Image Search via CLIP - Finetuner documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=91d0f0d1c444bdcb17a68e833c7a53903343c195" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../../_static/main.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: #4d4d4d;
  --color-brand-primary: #009191;
  --color-brand-content: #009191;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
    <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
    <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
    <header class="mobile-header">
        <div class="header-left">
            <label class="nav-overlay-icon" for="__navigation">
                <div class="visually-hidden">Toggle site navigation sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-menu"></use>
                    </svg>
                </i>
            </label>
        </div>
        <div class="header-center">
            <a href="../../">
                <div class="brand">Finetuner  documentation</div>
            </a>
        </div>
        <div class="header-right">
            <div class="theme-toggle-container theme-toggle-header">
                <button class="theme-toggle">
                    <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                    <svg class="theme-icon-when-auto">
                        <use href="#svg-sun-half"></use>
                    </svg>
                    <svg class="theme-icon-when-dark">
                        <use href="#svg-moon"></use>
                    </svg>
                    <svg class="theme-icon-when-light">
                        <use href="#svg-sun"></use>
                    </svg>
                </button>
            </div>
            <label class="toc-overlay-icon toc-header-icon" for="__toc">
                <div class="visually-hidden">Toggle table of contents sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-toc"></use>
                    </svg>
                </i>
            </label>
        </div>
    </header>
    <aside class="sidebar-drawer">
        <div class="sidebar-container">
            
            <div class="sidebar-sticky"><a class="sidebar-brand" href="../../">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/logo-light.svg" alt="Light Logo" />
    <img class="sidebar-logo only-dark" src="../../_static/logo-dark.svg" alt="Dark Logo" />
  </div>
  
  
</a>
<div class="sd-d-flex-row sd-align-major-spaced">
  <a class="github-button" href="https://github.com/jina-ai/finetuner" data-icon="octicon-star" data-show-count="true" aria-label="Star jina-ai/jina on GitHub" style="opacity: 0;">Star</a>
  
</div><form class="sidebar-search-container" method="get" action="../../search/" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
    <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../get-started/how-it-works/"><svg aria-hidden="true" class="sd-octicon sd-octicon-question" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm9 3a1 1 0 11-2 0 1 1 0 012 0zM6.92 6.085c.081-.16.19-.299.34-.398.145-.097.371-.187.74-.187.28 0 .553.087.738.225A.613.613 0 019 6.25c0 .177-.04.264-.077.318a.956.956 0 01-.277.245c-.076.051-.158.1-.258.161l-.007.004a7.728 7.728 0 00-.313.195 2.416 2.416 0 00-.692.661.75.75 0 001.248.832.956.956 0 01.276-.245 6.3 6.3 0 01.26-.16l.006-.004c.093-.057.204-.123.313-.195.222-.149.487-.355.692-.662.214-.32.329-.702.329-1.15 0-.76-.36-1.348-.863-1.725A2.76 2.76 0 008 4c-.631 0-1.155.16-1.572.438-.413.276-.68.638-.849.977a.75.75 0 101.342.67z" fill-rule="evenodd"></path></svg> How Does it Work?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get-started/installation/"><svg aria-hidden="true" class="sd-octicon sd-octicon-desktop-download" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M4.927 5.427l2.896 2.896a.25.25 0 00.354 0l2.896-2.896A.25.25 0 0010.896 5H8.75V.75a.75.75 0 10-1.5 0V5H5.104a.25.25 0 00-.177.427z"></path><path d="M1.573 2.573a.25.25 0 00-.073.177v7.5a.25.25 0 00.25.25h12.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-3a.75.75 0 110-1.5h3A1.75 1.75 0 0116 2.75v7.5A1.75 1.75 0 0114.25 12h-3.727c.099 1.041.52 1.872 1.292 2.757A.75.75 0 0111.25 16h-6.5a.75.75 0 01-.565-1.243c.772-.885 1.192-1.716 1.292-2.757H1.75A1.75 1.75 0 010 10.25v-7.5A1.75 1.75 0 011.75 1h3a.75.75 0 010 1.5h-3a.25.25 0 00-.177.073zM6.982 12a5.72 5.72 0 01-.765 2.5h3.566a5.72 5.72 0 01-.765-2.5H6.982z"></path></svg> Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../walkthrough/"><svg aria-hidden="true" class="sd-octicon sd-octicon-list-ordered" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M2.003 2.5a.5.5 0 00-.723-.447l-1.003.5a.5.5 0 00.446.895l.28-.14V6H.5a.5.5 0 000 1h2.006a.5.5 0 100-1h-.503V2.5zM5 3.25a.75.75 0 01.75-.75h8.5a.75.75 0 010 1.5h-8.5A.75.75 0 015 3.25zm0 5a.75.75 0 01.75-.75h8.5a.75.75 0 010 1.5h-8.5A.75.75 0 015 8.25zm0 5a.75.75 0 01.75-.75h8.5a.75.75 0 010 1.5h-8.5a.75.75 0 01-.75-.75zM.924 10.32l.003-.004a.851.851 0 01.144-.153A.66.66 0 011.5 10c.195 0 .306.068.374.146a.57.57 0 01.128.376c0 .453-.269.682-.8 1.078l-.035.025C.692 11.98 0 12.495 0 13.5a.5.5 0 00.5.5h2.003a.5.5 0 000-1H1.146c.132-.197.351-.372.654-.597l.047-.035c.47-.35 1.156-.858 1.156-1.845 0-.365-.118-.744-.377-1.038-.268-.303-.658-.484-1.126-.484-.48 0-.84.202-1.068.392a1.858 1.858 0 00-.348.384l-.007.011-.002.004-.001.002-.001.001a.5.5 0 00.851.525zM.5 10.055l-.427-.26.427.26z" fill-rule="evenodd"></path></svg> Walkthrough</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../walkthrough/basic-concepts/">Basic Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../walkthrough/login/">Login</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../walkthrough/create-training-data/">Prepare Training Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../walkthrough/choose-backbone/">Backbone Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../walkthrough/run-job/">Run Job</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../walkthrough/save-model/">Save Artifact</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../walkthrough/inference/">Inference</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/budget/"><svg aria-hidden="true" class="sd-octicon sd-octicon-database" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M2.5 3.5c0-.133.058-.318.282-.55.227-.237.592-.484 1.1-.708C4.899 1.795 6.354 1.5 8 1.5c1.647 0 3.102.295 4.117.742.51.224.874.47 1.101.707.224.233.282.418.282.551 0 .133-.058.318-.282.55-.227.237-.592.484-1.1.708C11.101 5.205 9.646 5.5 8 5.5c-1.647 0-3.102-.295-4.117-.742-.51-.224-.874-.47-1.101-.707-.224-.233-.282-.418-.282-.551zM1 3.5c0-.626.292-1.165.7-1.59.406-.422.956-.767 1.579-1.041C4.525.32 6.195 0 8 0c1.805 0 3.475.32 4.722.869.622.274 1.172.62 1.578 1.04.408.426.7.965.7 1.591v9c0 .626-.292 1.165-.7 1.59-.406.422-.956.767-1.579 1.041C11.476 15.68 9.806 16 8 16c-1.805 0-3.475-.32-4.721-.869-.623-.274-1.173-.62-1.579-1.04-.408-.426-.7-.965-.7-1.591v-9zM2.5 8V5.724c.241.15.503.286.779.407C4.525 6.68 6.195 7 8 7c1.805 0 3.475-.32 4.722-.869.275-.121.537-.257.778-.407V8c0 .133-.058.318-.282.55-.227.237-.592.484-1.1.708C11.101 9.705 9.646 10 8 10c-1.647 0-3.102-.295-4.117-.742-.51-.224-.874-.47-1.101-.707C2.558 8.318 2.5 8.133 2.5 8zm0 2.225V12.5c0 .133.058.318.282.55.227.237.592.484 1.1.708 1.016.447 2.471.742 4.118.742 1.647 0 3.102-.295 4.117-.742.51-.224.874-.47 1.101-.707.224-.233.282-.418.282-.551v-2.275c-.241.15-.503.285-.778.406-1.247.549-2.917.869-4.722.869-1.805 0-3.475-.32-4.721-.869a6.236 6.236 0 01-.779-.406z" fill-rule="evenodd"></path></svg> How much data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/negative-mining/"><svg aria-hidden="true" class="sd-octicon sd-octicon-telescope" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M14.184 1.143a1.75 1.75 0 00-2.502-.57L.912 7.916a1.75 1.75 0 00-.53 2.32l.447.775a1.75 1.75 0 002.275.702l11.745-5.656a1.75 1.75 0 00.757-2.451l-1.422-2.464zm-1.657.669a.25.25 0 01.358.081l1.422 2.464a.25.25 0 01-.108.35l-2.016.97-1.505-2.605 1.85-1.26zM9.436 3.92l1.391 2.41-5.42 2.61-.942-1.63 4.97-3.39zM3.222 8.157l-1.466 1a.25.25 0 00-.075.33l.447.775a.25.25 0 00.325.1l1.598-.769-.83-1.436zm6.253 2.306a.75.75 0 00-.944-.252l-1.809.87a.75.75 0 00-.293.253L4.38 14.326a.75.75 0 101.238.848l1.881-2.75v2.826a.75.75 0 001.5 0v-2.826l1.881 2.75a.75.75 0 001.238-.848l-2.644-3.863z" fill-rule="evenodd"></path></svg> Negative Mining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/using-callbacks/"><svg aria-hidden="true" class="sd-octicon sd-octicon-link" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z" fill-rule="evenodd"></path></svg> Using Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/linear-probe/"><svg aria-hidden="true" class="sd-octicon sd-octicon-pin" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M4.456.734a1.75 1.75 0 012.826.504l.613 1.327a3.081 3.081 0 002.084 1.707l2.454.584c1.332.317 1.8 1.972.832 2.94L11.06 10l3.72 3.72a.75.75 0 11-1.061 1.06L10 11.06l-2.204 2.205c-.968.968-2.623.5-2.94-.832l-.584-2.454a3.081 3.081 0 00-1.707-2.084l-1.327-.613a1.75 1.75 0 01-.504-2.826L4.456.734zM5.92 1.866a.25.25 0 00-.404-.072L1.794 5.516a.25.25 0 00.072.404l1.328.613A4.582 4.582 0 015.73 9.63l.584 2.454a.25.25 0 00.42.12l5.47-5.47a.25.25 0 00-.12-.42L9.63 5.73a4.581 4.581 0 01-3.098-2.537L5.92 1.866z" fill-rule="evenodd"></path></svg> Projection Head</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/advanced-losses-and-optimizers/"><svg aria-hidden="true" class="sd-octicon sd-octicon-mortar-board" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M7.693 1.066a.75.75 0 01.614 0l7.25 3.25a.75.75 0 010 1.368L13 6.831v2.794c0 1.024-.81 1.749-1.66 2.173-.893.447-2.075.702-3.34.702-.278 0-.55-.012-.816-.036a.75.75 0 01.133-1.494c.22.02.45.03.683.03 1.082 0 2.025-.221 2.67-.543.69-.345.83-.682.83-.832V7.503L8.307 8.934a.75.75 0 01-.614 0L4 7.28v1.663c.296.105.575.275.812.512.438.438.688 1.059.688 1.796v3a.75.75 0 01-.75.75h-3a.75.75 0 01-.75-.75v-3c0-.737.25-1.358.688-1.796.237-.237.516-.407.812-.512V6.606L.443 5.684a.75.75 0 010-1.368l7.25-3.25zM2.583 5L8 7.428 13.416 5 8 2.572 2.583 5zM2.5 11.25c0-.388.125-.611.25-.735a.704.704 0 01.5-.203c.19 0 .37.071.5.203.125.124.25.347.25.735v2.25H2.5v-2.25z" fill-rule="evenodd"></path></svg> Advanced losses and optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/finetuner-executor/"><svg aria-hidden="true" class="sd-octicon sd-octicon-gear" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M7.429 1.525a6.593 6.593 0 011.142 0c.036.003.108.036.137.146l.289 1.105c.147.56.55.967.997 1.189.174.086.341.183.501.29.417.278.97.423 1.53.27l1.102-.303c.11-.03.175.016.195.046.219.31.41.641.573.989.014.031.022.11-.059.19l-.815.806c-.411.406-.562.957-.53 1.456a4.588 4.588 0 010 .582c-.032.499.119 1.05.53 1.456l.815.806c.08.08.073.159.059.19a6.494 6.494 0 01-.573.99c-.02.029-.086.074-.195.045l-1.103-.303c-.559-.153-1.112-.008-1.529.27-.16.107-.327.204-.5.29-.449.222-.851.628-.998 1.189l-.289 1.105c-.029.11-.101.143-.137.146a6.613 6.613 0 01-1.142 0c-.036-.003-.108-.037-.137-.146l-.289-1.105c-.147-.56-.55-.967-.997-1.189a4.502 4.502 0 01-.501-.29c-.417-.278-.97-.423-1.53-.27l-1.102.303c-.11.03-.175-.016-.195-.046a6.492 6.492 0 01-.573-.989c-.014-.031-.022-.11.059-.19l.815-.806c.411-.406.562-.957.53-1.456a4.587 4.587 0 010-.582c.032-.499-.119-1.05-.53-1.456l-.815-.806c-.08-.08-.073-.159-.059-.19a6.44 6.44 0 01.573-.99c.02-.029.086-.075.195-.045l1.103.303c.559.153 1.112.008 1.529-.27.16-.107.327-.204.5-.29.449-.222.851-.628.998-1.189l.289-1.105c.029-.11.101-.143.137-.146zM8 0c-.236 0-.47.01-.701.03-.743.065-1.29.615-1.458 1.261l-.29 1.106c-.017.066-.078.158-.211.224a5.994 5.994 0 00-.668.386c-.123.082-.233.09-.3.071L3.27 2.776c-.644-.177-1.392.02-1.82.63a7.977 7.977 0 00-.704 1.217c-.315.675-.111 1.422.363 1.891l.815.806c.05.048.098.147.088.294a6.084 6.084 0 000 .772c.01.147-.038.246-.088.294l-.815.806c-.474.469-.678 1.216-.363 1.891.2.428.436.835.704 1.218.428.609 1.176.806 1.82.63l1.103-.303c.066-.019.176-.011.299.071.213.143.436.272.668.386.133.066.194.158.212.224l.289 1.106c.169.646.715 1.196 1.458 1.26a8.094 8.094 0 001.402 0c.743-.064 1.29-.614 1.458-1.26l.29-1.106c.017-.066.078-.158.211-.224a5.98 5.98 0 00.668-.386c.123-.082.233-.09.3-.071l1.102.302c.644.177 1.392-.02 1.82-.63.268-.382.505-.789.704-1.217.315-.675.111-1.422-.364-1.891l-.814-.806c-.05-.048-.098-.147-.088-.294a6.1 6.1 0 000-.772c-.01-.147.039-.246.088-.294l.814-.806c.475-.469.679-1.216.364-1.891a7.992 7.992 0 00-.704-1.218c-.428-.609-1.176-.806-1.82-.63l-1.103.303c-.066.019-.176.011-.299-.071a5.991 5.991 0 00-.668-.386c-.133-.066-.194-.158-.212-.224L10.16 1.29C9.99.645 9.444.095 8.701.031A8.094 8.094 0 008 0zm1.5 8a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0zM11 8a3 3 0 11-6 0 3 3 0 016 0z" fill-rule="evenodd"></path></svg> Use FinetunerExecutor inside a Jina Flow</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Finetuning Tasks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../text_to_text/">Text-to-Text Search via BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../image_to_image/">Image-to-Image Search via ResNet50</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Text-to-Image Search via CLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multilingual_text_to_image/">Multilingual Text-to-Image Search with MultilingualCLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mesh_to_mesh/">3D Mesh-to-3D Mesh Search via PointNet++</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api-rst/"><span class="fab fa-python"></span> Python API</a></li>
</ul>

    <p class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul>
        <li class="toctree-l1">
            <a class="reference external" href="https://docs.jina.ai">
                <img class="sidebar-ecosys-logo only-light-line" src="../../_static/search-light.svg">
                <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/search-dark.svg">
                Jina</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://cloud.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/hub-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/hub-dark.svg">
            Jina Hub</a></li>
        <li class="toctree-l1"><a class="reference internal" href="#">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/finetuner-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/finetuner-dark.svg">
            Finetuner</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://docarray.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/docarray-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/docarray-dark.svg">
            DocArray</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://clip-as-service.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/cas-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/cas-dark.svg">
            CLIP-as-service</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://github.com/jina-ai/jcloud">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/JCloud-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/JCloud-dark.svg">
            JCloud</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://github.com/jina-ai/now">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/now-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/now-dark.svg">
            NOW</a></li>
    </ul>
</div>
</div>

            </div>
            
        </div>
    </aside>
    <div class="main">
        <div class="content">
            <div class="article-container">
                <a href="#" class="back-to-top muted-link">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
                    </svg>
                    <span>Back to top</span>
                </a>
                <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
                        <button class="theme-toggle">
                            <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                            <svg class="theme-icon-when-auto">
                                <use href="#svg-sun-half"></use>
                            </svg>
                            <svg class="theme-icon-when-dark">
                                <use href="#svg-moon"></use>
                            </svg>
                            <svg class="theme-icon-when-light">
                                <use href="#svg-sun"></use>
                            </svg>
                        </button>
                    </div>
                    <label class="toc-overlay-icon toc-content-icon"
                           for="__toc">
                        <div class="visually-hidden">Toggle table of contents sidebar</div>
                        <i class="icon">
                            <svg>
                                <use href="#svg-toc"></use>
                            </svg>
                        </i>
                    </label>
                </div>
                <article role="main">
                    <!-- #region id="3UCyCMPcvLGw" -->
<section class="tex2jax_ignore mathjax_ignore" id="text-to-image-search-via-clip">
<h1>Text-to-Image Search via CLIP<a class="headerlink" href="#text-to-image-search-via-clip" title="Permalink to this heading">#</a></h1>
<p><a href="https://colab.research.google.com/drive/1yKnmy2Qotrh3OhgwWRsMWPFwOSAecBxg?usp=sharing"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"></a></p>
<p>Traditionally, searching images from text (text-image-retrieval) relies heavily on human annotations, this is commonly referred to as <em>Text/Tag-based Image Retrieval (TBIR)</em>.</p>
<p>The <a class="reference external" href="https://github.com/openai/CLIP">OpenAI CLIP</a> model maps the dense vectors extracted from text and image into the same semantic space and produces a strong zero-shot model to measure the similarity between text and images.</p>
<p>This guide will showcase fine-tuning a <code class="docutils literal notranslate"><span class="pre">CLIP</span></code> model for text-to-image retrieval.</p>
<p><em>Note, please consider switching to GPU/TPU Runtime for faster inference.</em></p>
<section id="install">
<h2>Install<a class="headerlink" href="#install" title="Permalink to this heading">#</a></h2>
<!-- #endregion -->
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!pip install &#39;finetuner[full]&#39;
</pre></div>
</div>
<!-- #region id="GXddluSIwCGW" -->
</section>
<section id="task">
<h2>Task<a class="headerlink" href="#task" title="Permalink to this heading">#</a></h2>
<p>We’ll be fine-tuning CLIP on the <a class="reference external" href="https://github.com/xuewyang/Fashion_Captioning">fashion captioning dataset</a> which contains information about fashion products.</p>
<p>For each product, the dataset contains a title and images of multiple variants of the product. We constructed a parent <a class="reference external" href="https://docarray.jina.ai/fundamentals/document/#document"><code class="docutils literal notranslate"><span class="pre">Document</span></code></a> for each picture, which contains two <a class="reference external" href="https://docarray.jina.ai/fundamentals/document/nested/#nested-structure">chunks</a>: an image document and a text document holding the description of the product.</p>
<!-- #endregion -->
<!-- #region id="EVBez7dHwIye" -->
</section>
<section id="data">
<h2>Data<a class="headerlink" href="#data" title="Permalink to this heading">#</a></h2>
<p>Our journey starts locally. We have to <a class="reference external" href="https://finetuner.jina.ai/walkthrough/create-training-data/">prepare the data and push it to the Jina AI Cloud</a> and Finetuner will be able to get the dataset by its name. For this example,
we already prepared the data, and we’ll provide the names of training and evaluation data (<code class="docutils literal notranslate"><span class="pre">fashion-train-data-clip</span></code> and <code class="docutils literal notranslate"><span class="pre">fashion-eval-data-clip</span></code>) directly to Finetuner.
In addition, we also provide labeled queries and an index of labeled documents for evaluating the retrieval capabilities of the resulting fine-tuned model stored in the datasets <code class="docutils literal notranslate"><span class="pre">fashion-eval-data-queries</span></code> and <code class="docutils literal notranslate"><span class="pre">fashion-eval-data-index</span></code>.</p>
<div class="admonition-push-data-to-the-cloud admonition">
<p class="admonition-title">Push data to the cloud</p>
<p>We don’t require you to push data to the Jina AI Cloud by yourself. Instead of a name, you can provide a <code class="docutils literal notranslate"><span class="pre">DocumentArray</span></code> and Finetuner will do the job for you.
When working with documents where images are stored locally, please call <code class="docutils literal notranslate"><span class="pre">doc.load_uri_to_blob()</span></code> to reduce network transmission and speed up training.</p>
</div>
<!-- #endregion -->
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">finetuner</span>
<span class="kn">from</span> <span class="nn">docarray</span> <span class="kn">import</span> <span class="n">DocumentArray</span><span class="p">,</span> <span class="n">Document</span>

<span class="n">finetuner</span><span class="o">.</span><span class="n">login</span><span class="p">(</span><span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="o">.</span><span class="n">pull</span><span class="p">(</span><span class="s1">&#39;finetuner/fashion-train-data-clip&#39;</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">eval_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="o">.</span><span class="n">pull</span><span class="p">(</span><span class="s1">&#39;finetuner/fashion-eval-data-clip&#39;</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">query_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="o">.</span><span class="n">pull</span><span class="p">(</span><span class="s1">&#39;finetuner/fashion-eval-data-queries&#39;</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">index_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="o">.</span><span class="n">pull</span><span class="p">(</span><span class="s1">&#39;finetuner/fashion-eval-data-index&#39;</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">train_data</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<!-- #region id="AE87a5Nvwd7q" -->
</section>
<section id="backbone-model">
<h2>Backbone model<a class="headerlink" href="#backbone-model" title="Permalink to this heading">#</a></h2>
<p>Currently, we support several CLIP variations from <a class="reference external" href="https://github.com/mlfoundations/open_clip">open-clip</a> for text to image retrieval tasks.</p>
<p>However, you can see all available models either in <a class="reference external" href="https://finetuner.jina.ai/walkthrough/choose-backbone/">choose backbone</a> section or by calling <code class="docutils literal notranslate"><span class="pre">finetuner.describe_models()</span></code>.</p>
<!-- #endregion -->
<!-- #region id="81fh900Bxgkn" -->
</section>
<section id="fine-tuning">
<h2>Fine-tuning<a class="headerlink" href="#fine-tuning" title="Permalink to this heading">#</a></h2>
<p>Now that we have the training and evaluation datasets loaded as <code class="docutils literal notranslate"><span class="pre">DocumentArray</span></code>s and selected our model, we can start our fine-tuning run.</p>
<!-- #endregion -->
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">finetuner.callback</span> <span class="kn">import</span> <span class="n">EvaluationCallback</span>

<span class="n">run</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s1">&#39;openai/clip-vit-base-patch32&#39;</span><span class="p">,</span>
    <span class="n">train_data</span><span class="o">=</span><span class="s1">&#39;finetuner/fashion-train-data-clip&#39;</span><span class="p">,</span>
    <span class="n">eval_data</span><span class="o">=</span><span class="s1">&#39;finetuner/fashion-eval-data-clip&#39;</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;CLIPLoss&#39;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span>
        <span class="n">EvaluationCallback</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s1">&#39;clip-text&#39;</span><span class="p">,</span>
            <span class="n">index_model</span><span class="o">=</span><span class="s1">&#39;clip-vision&#39;</span><span class="p">,</span>
            <span class="n">query_data</span><span class="o">=</span><span class="s1">&#39;finetuner/fashion-eval-data-queries&#39;</span><span class="p">,</span>
            <span class="n">index_data</span><span class="o">=</span><span class="s1">&#39;finetuner/fashion-eval-data-index&#39;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<!-- #region id="QPDmFdubxzUE" -->
<p>Let’s understand what this piece of code does:</p>
<ul class="simple">
<li><p>We start with providing <code class="docutils literal notranslate"><span class="pre">model</span></code>, names of training and evaluation data.</p></li>
<li><p>We also provide some hyperparameters such as number of <code class="docutils literal notranslate"><span class="pre">epochs</span></code> and a <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>.</p></li>
<li><p>We use <code class="docutils literal notranslate"><span class="pre">CLIPLoss</span></code> to optimize the CLIP model.</p></li>
<li><p>We use an evaluation callback, which uses the <code class="docutils literal notranslate"><span class="pre">'clip-text'</span></code> model for encoding the text queries and the <code class="docutils literal notranslate"><span class="pre">'clip-vision'</span></code> model for encoding the images in <code class="docutils literal notranslate"><span class="pre">'fashion-eval-data-index'</span></code>.</p></li>
</ul>
<!-- #endregion -->
<!-- #region id="qKv3VcMKyG8d" -->
</section>
<section id="monitoring">
<h2>Monitoring<a class="headerlink" href="#monitoring" title="Permalink to this heading">#</a></h2>
<p>Now that we’ve created a run, let’s see its status. You can monitor the run by checking the status - <code class="docutils literal notranslate"><span class="pre">run.status()</span></code> and - the logs - <code class="docutils literal notranslate"><span class="pre">run.logs()</span></code> or - <code class="docutils literal notranslate"><span class="pre">run.stream_logs()</span></code>.</p>
<!-- #endregion -->
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># note, the fine-tuning might takes 20~ minutes</span>
<span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">run</span><span class="o">.</span><span class="n">stream_logs</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span>
</pre></div>
</div>
<!-- #region id="xi49YlQsyXbi" -->
<p>Since some runs might take up to several hours/days, it’s important to know how to reconnect to Finetuner and retrieve your run.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">finetuner</span>

<span class="n">finetuner</span><span class="o">.</span><span class="n">login</span><span class="p">()</span>
<span class="n">run</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">get_run</span><span class="p">(</span><span class="n">run</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
<p>You can continue monitoring the run by checking the status - <code class="docutils literal notranslate"><span class="pre">finetuner.run.Run.status()</span></code> or the logs - <code class="docutils literal notranslate"><span class="pre">finetuner.run.Run.logs()</span></code>.</p>
<!-- #endregion -->
<!-- #region id="Xeq_aVRxyqlW" -->
</section>
<section id="evaluating">
<h2>Evaluating<a class="headerlink" href="#evaluating" title="Permalink to this heading">#</a></h2>
<p>Our <code class="docutils literal notranslate"><span class="pre">EvaluationCallback</span></code> during fine-tuning ensures that after each epoch, an evaluation of our model is run. We can access the results of the last evaluation in the logs as follows <code class="docutils literal notranslate"><span class="pre">print(run.logs())</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w">  </span>Training<span class="w"> </span><span class="o">[</span><span class="m">5</span>/5<span class="o">]</span><span class="w"> </span>━━━━<span class="w"> </span><span class="m">195</span>/195<span class="w"> </span><span class="m">0</span>:00…<span class="w"> </span><span class="m">0</span>:0…<span class="w"> </span>•<span class="w"> </span>loss:<span class="w"> </span><span class="m">2</span>.419<span class="w"> </span>•<span class="w"> </span>val_loss:<span class="w"> </span><span class="m">2</span>.803
<span class="o">[</span><span class="m">13</span>:32:41<span class="o">]</span><span class="w"> </span>INFO<span class="w">     </span>Done<span class="w"> </span>✨<span class="w">                              </span>__main__.py:195
<span class="w">           </span>DEBUG<span class="w">    </span>Finetuning<span class="w"> </span>took<span class="w"> </span><span class="m">0</span><span class="w"> </span>days,<span class="w"> </span><span class="m">0</span><span class="w"> </span>hours<span class="w"> </span><span class="m">5</span><span class="w"> </span>minutes<span class="w"> </span>and<span class="w"> </span><span class="m">30</span><span class="w"> </span>seconds
<span class="w">           </span>DEBUG<span class="w">    </span>Metric:<span class="w"> </span><span class="s1">&#39;clip-text-to-clip-vision_precision_at_k&#39;</span><span class="w"> </span>Value:<span class="w"> </span><span class="m">0</span>.28532<span class="w">                                                   </span>
<span class="w">           </span>DEBUG<span class="w">    </span>Metric:<span class="w"> </span><span class="s1">&#39;clip-text-to-clip-vision_hit_at_k&#39;</span><span class="w"> </span>Value:<span class="w"> </span><span class="m">0</span>.94282<span class="w">                                            </span>
<span class="w">           </span>DEBUG<span class="w">    </span>Metric:<span class="w"> </span><span class="s1">&#39;clip-text-to-clip-vision_average_precision&#39;</span><span class="w"> </span>Value:<span class="w"> </span><span class="m">0</span>.53372<span class="w">                             </span>
<span class="w">           </span>DEBUG<span class="w">    </span>Metric:<span class="w"> </span><span class="s1">&#39;clip-text-to-clip-vision_reciprocal_rank&#39;</span><span class="w"> </span>Value:<span class="w"> </span><span class="m">0</span>.67706<span class="w">                               </span>
<span class="w">           </span>DEBUG<span class="w">    </span>Metric:<span class="w"> </span><span class="s1">&#39;clip-text-to-clip-vision_dcg_at_k&#39;</span><span class="w"> </span>Value:<span class="w"> </span><span class="m">2</span>.71247<span class="w">                                      </span>
...
</pre></div>
</div>
<!-- #endregion -->
<!-- #region id="h3qC3yAcy-Es" -->
</section>
<section id="saving">
<h2>Saving<a class="headerlink" href="#saving" title="Permalink to this heading">#</a></h2>
<p>After the run has finished successfully, you can download the tuned model on your local machine:</p>
<!-- #endregion -->
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">artifact</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">save_artifact</span><span class="p">(</span><span class="s1">&#39;clip-model&#39;</span><span class="p">)</span>
</pre></div>
</div>
<!-- #region id="8_VGjKq3zDx9" -->
</section>
<section id="inference">
<h2>Inference<a class="headerlink" href="#inference" title="Permalink to this heading">#</a></h2>
<p>Now you saved the <code class="docutils literal notranslate"><span class="pre">artifact</span></code> into your host machine,
let’s use the fine-tuned model to encode a new <code class="docutils literal notranslate"><span class="pre">Document</span></code>:</p>
<!-- #endregion -->
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text_da</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="p">([</span><span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;some text to encode&#39;</span><span class="p">)])</span>
<span class="n">image_da</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="p">([</span><span class="n">Document</span><span class="p">(</span><span class="n">uri</span><span class="o">=</span><span class="s1">&#39;https://upload.wikimedia.org/wikipedia/commons/4/4e/Single_apple.png&#39;</span><span class="p">)])</span>

<span class="n">clip_text_encoder</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">artifact</span><span class="o">=</span><span class="n">artifact</span><span class="p">,</span> <span class="n">select_model</span><span class="o">=</span><span class="s1">&#39;clip-text&#39;</span><span class="p">)</span>
<span class="n">clip_image_encoder</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">artifact</span><span class="o">=</span><span class="n">artifact</span><span class="p">,</span> <span class="n">select_model</span><span class="o">=</span><span class="s1">&#39;clip-vision&#39;</span><span class="p">)</span>

<span class="n">finetuner</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">clip_text_encoder</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">text_da</span><span class="p">)</span>
<span class="n">finetuner</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">clip_image_encoder</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">image_da</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">text_da</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">image_da</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<!-- #region id="LzMbR7VgzXtA" -->
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">512</span><span class="o">)</span>
<span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">512</span><span class="o">)</span>
</pre></div>
</div>
<div class="admonition-what-is-select-model admonition">
<p class="admonition-title">what is select_model?</p>
<p>When fine-tuning CLIP, we are fine-tuning the CLIPVisionEncoder and CLIPTextEncoder in parallel.
The artifact contains two models: <code class="docutils literal notranslate"><span class="pre">clip-vision</span></code> and <code class="docutils literal notranslate"><span class="pre">clip-text</span></code>.
The parameter <code class="docutils literal notranslate"><span class="pre">select_model</span></code> tells finetuner which model to use for inference, in the above example,
we use <code class="docutils literal notranslate"><span class="pre">clip-text</span></code> to encode a Document with text content.</p>
</div>
<div class="admonition-inference-with-onnx admonition">
<p class="admonition-title">Inference with ONNX</p>
<p>In case you set <code class="docutils literal notranslate"><span class="pre">to_onnx=True</span></code> when calling <code class="docutils literal notranslate"><span class="pre">finetuner.fit</span></code> function,
please use <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">=</span> <span class="pre">finetuner.get_model(artifact,</span> <span class="pre">is_onnx=True)</span></code></p>
</div>
<!-- #endregion -->
<!-- #region id="LHyMm_M1zxdt" -->
</section>
<section id="advanced-wise-ft">
<h2>Advanced: WiSE-FT<a class="headerlink" href="#advanced-wise-ft" title="Permalink to this heading">#</a></h2>
<p>WiSE-FT, proposed by Mitchell et al. in <a class="reference external" href="https://arxiv.org/abs/2109.01903">Robust fine-tuning of zero-shot models</a>,
has been proven to be an effective way for fine-tuning models with a strong zero-shot capability,
such as CLIP.
As was introduced in the paper:</p>
<blockquote>
<div><p>Large pre-trained models such as CLIP or ALIGN offer consistent accuracy across a range of data distributions when performing zero-shot inference (i.e., without fine-tuning on a specific dataset). Although existing fine-tuning methods substantially improve accuracy on a given target distribution, they often reduce robustness to distribution shifts. We address this tension by introducing a simple and effective method for improving robustness while fine-tuning: ensembling the weights of the zero-shot and fine-tuned models (WiSE-FT).</p>
</div></blockquote>
<p>Finetuner allows you to apply WiSE-FT easily,
all you need to do is use the <code class="docutils literal notranslate"><span class="pre">WiSEFTCallback</span></code>.
Finetuner will trigger the callback when the fine-tuning job is finished and merge the weights between the pre-trained model and the fine-tuned model:</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="w">from finetuner.callback import WiSEFTCallback</span>

<span class="w">run = finetuner.fit(</span>
<span class="w"> </span>   model=&#39;ViT-B-32#openai&#39;,
<span class="w"> </span>   ...,
<span class="w"> </span>   loss=&#39;CLIPLoss&#39;,
<span class="gd">-   callbacks=[],</span>
<span class="gi">+   callbacks=[WiSEFTCallback(alpha=0.5)],</span>
<span class="w">)</span>
</pre></div>
</div>
<p>The value you set for <code class="docutils literal notranslate"><span class="pre">alpha</span></code> should be greater than or equal to 0 and less than or equal to 1:</p>
<ul class="simple">
<li><p>if <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is a float between 0 and 1, we merge the weights between the pre-trained model and the fine-tuned model.</p></li>
<li><p>if <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is 0, the fine-tuned model is identical to the pre-trained model.</p></li>
<li><p>if <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is 1, the pre-trained weights will not be utilized.</p></li>
</ul>
<p>That’s it! Check out <a class="reference external" href="https://clip-as-service.jina.ai/user-guides/finetuner/?highlight=finetuner#fine-tune-models">clip-as-service</a> to learn how to plug in a fine-tuned CLIP model to our CLIP-specific service.</p>
<!-- #endregion -->
<!-- #region id="tpm8eVRFX20B" -->
</section>
<section id="before-and-after">
<h2>Before and after<a class="headerlink" href="#before-and-after" title="Permalink to this heading">#</a></h2>
<p>We can directly compare the results of our fine-tuned model with a pre-trained clip model by displaying the matches each model has for the same query. While the differences between the results of the two models are quite subtle for some queries, the examples below clearly show that finetuning increases the quality of the search results:</p>
<!-- #endregion -->
<!-- #region id="C30UVpHDX4HF" -->
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>Results for query: &quot;nightingale tee jacket&quot; using a zero-shot model (top) and the fine-tuned model (bottom)
</pre></div>
</div>
<p><img alt="clip-example-pt" src="https://user-images.githubusercontent.com/6599259/212634395-6f336d39-cda7-425d-80a2-10facae3b824.png" /></p>
<p><img alt="clip-example-ft" src="https://user-images.githubusercontent.com/6599259/212634112-a44c6c4c-2cc1-4dfb-8e29-0d02b2d6b95c.png" /></p>
<!-- #endregion -->
</section>
</section>

                </article>
            </div>
            <footer>
                
                <div class="related-pages">
                    <a class="next-page" href="../multilingual_text_to_image/">
                        <div class="page-info">
                            <div class="context">
                                <span>Next</span>
                            </div>
                            <div class="title">Multilingual Text-to-Image Search with MultilingualCLIP</div>
                        </div>
                        <svg class="furo-related-icon">
                            <use href="#svg-arrow-right"></use>
                        </svg>
                    </a>
                    <a class="prev-page" href="../image_to_image/">
                        <svg class="furo-related-icon">
                            <use href="#svg-arrow-right"></use>
                        </svg>
                        <div class="page-info">
                            <div class="context">
                                <span>Previous</span>
                            </div>
                            
                            <div class="title">Image-to-Image Search via ResNet50</div>
                            
                        </div>
                    </a>
                </div>
                <div class="bottom-of-page">
                    <div class="left-details">
                        <div class="copyright">
                            Copyright &#169; Jina AI Limited. All rights reserved.
                        </div><div class="last-updated">
                            Last updated on Feb 15, 2023</div>
                    </div>
                    <div class="right-details">
                        <div class="social-btns">
                            <a class='social-btn' href="https://github.com/jina-ai/finetuner/" aria-label="GitHub"
                               target="_blank" rel="noreferrer"> <i class="fab fa-github"></i></a>
                            <a class='social-btn' href="https://slack.jina.ai" aria-label="Slack" target="_blank"
                               rel="noreferrer"> <i class="fab fa-slack"></i></a>
                            <a class='social-btn' href="https://youtube.com/c/jina-ai" aria-label="YouTube"
                               target="_blank" rel="noreferrer"> <i class="fab fa-youtube"></i></a>
                            <a class='social-btn' href="https://twitter.com/JinaAI_" aria-label="Twitter"
                               target="_blank" rel="noreferrer"> <i class="fab fa-twitter"></i></a>
                            <a class='social-btn' href="https://www.linkedin.com/company/jinaai/" aria-label="LinkedIn"
                               target="_blank" rel="noreferrer"> <i class="fab fa-linkedin"></i></a>
                        </div>
                    </div>
                </div>
                
            </footer>
        </div>
        <aside class="toc-drawer">
            
            
            <div class="toc-sticky toc-scroll">
                <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
                </div>
                <div class="toc-tree-container">
                    <div class="toc-tree">
                        <ul>
<li><a class="reference internal" href="#">Text-to-Image Search via CLIP</a><ul>
<li><a class="reference internal" href="#install">Install</a></li>
<li><a class="reference internal" href="#task">Task</a></li>
<li><a class="reference internal" href="#data">Data</a></li>
<li><a class="reference internal" href="#backbone-model">Backbone model</a></li>
<li><a class="reference internal" href="#fine-tuning">Fine-tuning</a></li>
<li><a class="reference internal" href="#monitoring">Monitoring</a></li>
<li><a class="reference internal" href="#evaluating">Evaluating</a></li>
<li><a class="reference internal" href="#saving">Saving</a></li>
<li><a class="reference internal" href="#inference">Inference</a></li>
<li><a class="reference internal" href="#advanced-wise-ft">Advanced: WiSE-FT</a></li>
<li><a class="reference internal" href="#before-and-after">Before and after</a></li>
</ul>
</li>
</ul>

                    </div>
                </div>
            </div>
            
            
        </aside>

        <qa-bot
            token="vizI4XaM1li8kQW2kQOiiBjtk02hzBDl0Em8lBjpzAKsjhX_z03mix_i3wKpiA=="
            theme="infer"
            target="_self"
            orientation="bottom-right"
            title="Finetuner"
            description="Task-oriented finetuning for better embeddings on neural search"
            show-tip>
          <template>
            <dl>
             <dt>You can ask questions about our docs. Try:</dt>
             <dd>What is Finetuner?</dd>
             <dd>How does Finetuner Work?</dd>
             <dd>What makes Finetuner unique?</dd>
            </dl>
          </template>
          <template slot="texts">
            <span for="tip">Hi there 👋
         Ask our docs!</span>
            <span for="unknownAnswerText">😵‍💫 I'm sorry but I don't know the answer.</span>
          </template>
        </qa-bot>
</div>
<img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=e0caedb8-a833-4e85-983d-d3394a5f16d2" /><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vue@2/dist/vue.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/qabot"></script>
    <script src="../../_static/source-in-links.js"></script>
    </body>
</html>