{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3D Mesh-to-3D Mesh Search via Pointnet++\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1lIMDFkUVsWMshU-akJ_hwzBfJ37zLFzU?usp=sharing\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n",
        "\n",
        "Finding similar 3D Meshes can become very time consuming. To support this task, one can build search systems. To directly search on the 3D meshes without relying on metadata one can use encoder model which extract create a point cloud from the mesh and encode it into vector dense representations which can be compared to each other. To enable those models to detect the right attributes of an 3D Mesh, this tutorial show you how to use Finetuner to train and use a model for 3D mesh search system."
      ],
      "metadata": {
        "id": "C0RxIJmLkTGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "mk4gxLZnYJry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'finetuner[full]'"
      ],
      "metadata": {
        "id": "vDVkw65kkQcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "Finetuner supports an embedding model which is based on the Pytorch [implemention](https://github.com/yanx27/Pointnet_Pointnet2_pytorch) of the [PointNet++ model](https://proceedings.neurips.cc/paper/2017/file/d8bf84be3800d12f74d8b05e9b89836f-Paper.pdf). This tutorial will show you how to train and use this model for 3D mesh search.\n",
        "\n",
        "We demonstrate this on the [Modelnet40](https://modelnet.cs.princeton.edu/) dataset which consist of more than 12k 3D meshes of objects from 40 classes.\n",
        "Specifically, we want to build a search system, which can receive a 3D mehs and retrieves meshes of the same class.\n",
        "\n",
        "We will buid a dataset with some images for \n"
      ],
      "metadata": {
        "id": "q7Bb9o5ZHSZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "ModelNet40 consists of 9843 meshes provided for training and 2468 meshes for testing. Usually, you would have to download the [dataset](https://modelnet.cs.princeton.edu/) unzip it, [prepare it, and upload it to the Jina AI Cloud](https://https://finetuner.jina.ai/walkthrough/create-training-data/). After that, you can provide the name of the dataset used for the upload to Finetuner.\n",
        "\n",
        "For this tutorial, we already prepared the data and uploaded it. Specifically the training data is uploaded as `modelnet40-train`. For evaluating the model, we split the test set of the original dataset in 300 meshes, which serve as queries (`modelnet40-queries`) and 2168 meshes which serve as the mesh collection, which is searched in (`modelnet40-index`).\n",
        "\n",
        "Each 3D mesh in the dataset is represented by a [DocArray](https://github.com/docarray/docarray) Document object. It contains the uri (local filepath) of the original file and a tensor which contains a point cloud with 2048 3D points sampled from the mesh as explained in (TODO add link to documentation)\n",
        "\n",
        "The code below loads the data and prints a summary of the training datasets:"
      ],
      "metadata": {
        "id": "H1Yo3NuGP1Oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import finetuner\n",
        "from docarray import DocumentArray, Document\n",
        "\n",
        "finetuner.login(force=True)"
      ],
      "metadata": {
        "id": "uTDreSwfYGOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = DocumentArray.pull('modelnet40-train', show_progress=True)\n",
        "query_data = DocumentArray.pull('modelnet40-queries', show_progress=True)\n",
        "index_data = DocumentArray.pull('modelnet40-index', show_progress=True)\n",
        "\n",
        "train_data.summary()"
      ],
      "metadata": {
        "id": "Y-Um5gE8IORv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backbone model\n",
        "\n",
        "The model, we provide for 3d mesh encoding is called `pointnet++`. In the following, we show you how to train it on the modelnet training dataset."
      ],
      "metadata": {
        "id": "B3I_QUeFT_V0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Now that we have data for training and evaluation as well as the name of the model, which we want to train, we can configure and submit a fine-tuning run:"
      ],
      "metadata": {
        "id": "lqg0eY9oknLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from finetuner.callback import EvaluationCallback\n",
        "\n",
        "run = finetuner.fit(\n",
        "    model='pointnet++',\n",
        "    train_data='modelnet40-train',\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    learning_rate= 5e-4,\n",
        "    loss='TripletMarginLoss',\n",
        "    device='cpu',\n",
        "    callbacks=[\n",
        "        EvaluationCallback(\n",
        "            query_data='modelnet40-queries',\n",
        "            index_data='modelnet40-index',\n",
        "            batch_size=64,\n",
        "        )\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "rR22MbgITp8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's understand what this piece of code does:\n",
        "\n",
        "* We start with providing `model`, in our case \"pointnet++\".\n",
        "* Via the `train_data` parameter, we inform the Finetuner about the name of the dataset in the Jina AI Cloud\n",
        "* We also provide some hyper-parameters such as number of `epochs`, `batch_size`, and a `learning_rate`.\n",
        "* We use `TripletMarginLoss` to optimize the PointNet++ model.\n",
        "* We use an evaluation callback, which uses the fine-tuned model for encoding the text queries and meshes in the index data collection. It also accepts the `batch_size` attribute. By encoding 64 meshes at once, the evaluation gets faster.\n"
      ],
      "metadata": {
        "id": "ossT9LH1oh6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monitoring\n",
        "\n",
        "Now that we've created a run, let's see how it's processing. You can monitor the run by checking the status via `run.status()` and view the logs with `run.logs()`. To stream logs, call `run.stream_logs()`:"
      ],
      "metadata": {
        "id": "AsHsMJP6p7Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note, the fine-tuning might takes 20~ minutes\n",
        "for entry in run.stream_logs():\n",
        "    print(entry)"
      ],
      "metadata": {
        "id": "PCCRZ6PalsK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since some runs might take up to several hours/days, it's important to know how to reconnect to Finetuner and retrieve your run.\n",
        "\n",
        "```python\n",
        "import finetuner\n",
        "\n",
        "finetuner.login()\n",
        "run = finetuner.get_run(run.name)\n",
        "```\n",
        "\n",
        "You can continue monitoring the run by checking the status - `finetuner.run.Run.status()` or the logs - `finetuner.run.Run.logs()`.*kursiver Text*"
      ],
      "metadata": {
        "id": "zG7Uci-qqkzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating\n",
        "\n",
        "Our `EvaluationCallback` during fine-tuning ensures that after each epoch, an evaluation of our model is run. We can access the results of the last evaluation in the logs as follows `print(run.logs())`:\n",
        "\n",
        "```bash\n",
        "...\n",
        "...\n",
        "```\n"
      ],
      "metadata": {
        "id": "WgTrq9D5q0zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "After the run has finished successfully, you can download the tuned model on your local machine:"
      ],
      "metadata": {
        "id": "W4ZCKUOfq9oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact = run.save_artifact('pointnet_model')"
      ],
      "metadata": {
        "id": "K5UdKleiqd8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "Now you saved the `artifact` into your host machine,\n",
        "let's use the fine-tuned model to encode a new `Document`:\n",
        "\n",
        "```{admonition} Inference with ONNX\n",
        "In case you set `to_onnx=True` when calling `finetuner.fit` function,\n",
        "please use `model = finetuner.get_model(artifact, is_onnx=True)`\n",
        "```"
      ],
      "metadata": {
        "id": "JU3uUVyirTE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = DocumentArray([query_data[0]])\n",
        "\n",
        "model = finetuner.get_model(artifact=artifact, device='cuda')\n",
        "\n",
        "finetuner.encode(model=model, data=query)\n",
        "finetuner.encode(model=model, data=index_data)\n",
        "\n",
        "assert query.embeddings.shape == (1, 512)"
      ],
      "metadata": {
        "id": "rDGxi7kVq_sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally you can use the embeded `query` to find top-k visually related images within `index_data` as follows:"
      ],
      "metadata": {
        "id": "pfoc4YG4rrkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query.match(index_data, limit=10, metric='cosine')"
      ],
      "metadata": {
        "id": "_jGsSyedrsJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}