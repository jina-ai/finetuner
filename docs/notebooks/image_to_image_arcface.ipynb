{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p8jc8EyfruKw"
      },
      "source": [
        "# Image-to-Image Search with ArcFaceLoss\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1ZS9FmnR9FzO_JYGCPazFM7TcMNQl51xM?usp=sharing\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n",
        "\n",
        "Using image queries to search for visually similar images is a very popular use case. However, pre-trained models do not deliver the best results. Models are trained on general data that lack knowledge related to your specific task. Here's where Finetuner comes in! It enables you to easily add task-specific knowledge to a model.\n",
        "\n",
        "Where [another guide](https://finetuner.jina.ai/notebooks/image_to_image/) showed off fine-tuning with `TripletMarginLoss`, \n",
        "this guide will perform fine-tuning on a dataset with fewer classes, more documents per class and with training data that contains examples from every class in the evaluation data. To improve our performance in this case, we will use `ArcFaceLoss` as our loss function this time.\n",
        "\n",
        "*Note, please switch to a GPU/TPU Runtime or this will be extremely slow!*\n",
        "\n",
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdKH0S0FrwS3"
      },
      "outputs": [],
      "source": [
        "!pip install 'finetuner[full]'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7EliQdGCsdL0"
      },
      "source": [
        "## Task\n",
        "\n",
        "We will fine-tune ResNet50 on the [Stanford Cars Dataset](http://ai.stanford.edu/~jkrause/cars/car_dataset.html).\n",
        "This dataset consists of 196 classes across 16184 documents in total.\n",
        "Each class represents a single model of car, and consists of roughly 80 pictures of that model of car.\n",
        "\n",
        "In order to move documents in the same class (images of the same model of car) closer together and move documents of different classes apart, we use the `ArcFaceLoss` function. For more information on how this loss function works, as well as when to use it over `TripletmarginLoss`, see [Advanced Losses and Optimizers](https://finetuner.jina.ai/advanced-topics/advanced-losses-and-optimizers/)\n",
        "\n",
        "After fine-tuning, documents from each class should have similar embeddings, distinct from documents of other classes, meaning that embedding two images of the same model of car will result in similar output vectors."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M1sii3xdtD2y"
      },
      "source": [
        "## Data\n",
        "\n",
        "Our journey starts locally. We have to prepare the data and push it to the Jina AI Cloud and Finetuner will be able to get the dataset by its name. For this example,\n",
        "we've already prepared the data, and we'll provide Finetuner with just the names of training, query and index dataset (e.g. `stanford-cars-train`).\n",
        "\n",
        "```{important} \n",
        "You don't have to push your data to the Jina AI Cloud before fine-tuning. Instead of a name, you can provide a `DocumentArray` and Finetuner will do upload your data directly.\n",
        "Important: If your documents refer to locally stored images, please call `doc.load_uri_to_blob()` before starting Finetuner to reduce network transmission and speed up training.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0NfPGbTkNsc"
      },
      "outputs": [],
      "source": [
        "import finetuner\n",
        "from finetuner import DocumentArray, Document\n",
        "\n",
        "finetuner.login(force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONpXDwFBsqQS"
      },
      "outputs": [],
      "source": [
        "train_data = DocumentArray.pull('finetuner/stanford-cars-train', show_progress=True)\n",
        "query_data = DocumentArray.pull('finetuner/stanford-cars-query', show_progress=True)\n",
        "index_data = DocumentArray.pull('finetuner/stanford-cars-index', show_progress=True)\n",
        "\n",
        "train_data.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mUoY1jq0klwk"
      },
      "source": [
        "## Backbone model\n",
        "Now let's see which backbone models we can use. You can see all the available models by calling `finetuner.describe_models()`.\n",
        "\n",
        "\n",
        "For this example, we're gonna go with `resnet-base`, a model that has been trained on the [ImageNet](https://www.image-net.org/) classification task. In the next step, Finetuner will adapt this model, turning it into an embedding model instead."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xA7IIhIOk0h0"
      },
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Now that we have selected our model and loaded the training and evaluation datasets as `DocumentArray`s, we can start our fine-tuning run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGrHfz-2kVC7"
      },
      "outputs": [],
      "source": [
        "from finetuner.callback import EvaluationCallback\n",
        "\n",
        "run = finetuner.fit(\n",
        "    model='resnet-base',\n",
        "    train_data='finetuner/stanford-cars-train',\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    learning_rate=1e-3,\n",
        "    loss='ArcFaceLoss',\n",
        "    device='cuda',\n",
        "    sampler='random',\n",
        "    callbacks=[\n",
        "        EvaluationCallback(\n",
        "            query_data='finetuner/stanford-cars-query',\n",
        "            index_data='finetuner/stanford-cars-index',\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvoWipMlG5P"
      },
      "source": [
        "Let's understand what this piece of code does:\n",
        "\n",
        "* We select a `model`: `resnet-base`.\n",
        "* We also set `run_name` and `description`, which are optional,\n",
        "but strongly recommended so that you can access and retain information about your run.\n",
        "* We specify the training data (`train_data`).\n",
        "* We set `ArcFaceLoss` as our loss function.\n",
        "* We use `finetuner.callback.EvaluationCallback` for evaluation and specify the query and index datasets for it. `finetuner/stanford-cars-query` and `finetuner/stanford-cars-index` are two subsamples of the Stanford cars dataset that have no overlap with each other or our training data.\n",
        "* We set the number of training epochs (`epochs`) and the learning rate (`learning_rate`)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7ftSOH_olcak"
      },
      "source": [
        "## Monitoring\n",
        "\n",
        "Now that we've created a run, we can see its status. You can monitor the state of the run with `run.status()`, and use `run.logs()` or `run.stream_logs()` to see the logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k3hTskflI7e"
      },
      "outputs": [],
      "source": [
        "# note, the fine-tuning might takes 30~ minutes\n",
        "for entry in run.stream_logs():\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8O-Ms_El-lV"
      },
      "source": [
        "Since some runs might take up to several hours, it's important to know how to reconnect to Finetuner and retrieve your runs.\n",
        "\n",
        "```python\n",
        "import finetuner\n",
        "finetuner.login()\n",
        "\n",
        "run = finetuner.get_run(run.name)\n",
        "```\n",
        "\n",
        "You can continue monitoring the runs by checking the status - `finetuner.run.Run.status()` or the logs - `finetuner.run.Run.logs()`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMpQxydypeZ3"
      },
      "source": [
        "## Evaluating\n",
        "Currently, we don't have a user-friendly way to get evaluation metrics from the `finetuner.callback.EvaluationCallback` we initialized previously.\n",
        "What you can do for now is to call `run.logs()` after the end of the run and see the evaluation results:\n",
        "\n",
        "```bash\n",
        "Training [5/5] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 48/48 0:00:00 0:00:12 ‚Ä¢ loss: 13.986\n",
        "INFO     Done ‚ú®                                                                              __main__.py:195\n",
        "DEBUG    Finetuning took 0 days, 0 hours 3 minutes and 48 seconds                             __main__.py:197\n",
        "INFO     Metric: 'resnet_base_precision_at_k' before fine-tuning:  0.11575 after fine-tuning:    __main__.py:210\n",
        "0.53425\n",
        "INFO     Metric: 'resnet_base_recall_at_k' before fine-tuning:  0.05745 after fine-tuning:       __main__.py:210\n",
        "0.27113\n",
        "INFO     Metric: 'resnet_base_f1_score_at_k' before fine-tuning:  0.07631 after fine-tuning:     __main__.py:210\n",
        "0.35788\n",
        "INFO     Metric: 'resnet_base_hit_at_k' before fine-tuning:  0.82900 after fine-tuning: 0.94100  __main__.py:210\n",
        "INFO     Metric: 'resnet_base_average_precision' before fine-tuning:  0.52305 after fine-tuning: __main__.py:210\n",
        "0.79779\n",
        "INFO     Metric: 'resnet_base_reciprocal_rank' before fine-tuning:  0.64909 after fine-tuning:   __main__.py:210\n",
        "0.89224\n",
        "INFO     Metric: 'resnet_base_dcg_at_k' before fine-tuning:  1.30710 after fine-tuning: 4.52143  __main__.py:210\n",
        "INFO     Building the artifact ...                                                            __main__.py:215\n",
        "INFO     Pushing artifact to Jina AI Cloud ...                                                __main__.py:241\n",
        "[12:19:53] INFO     Artifact pushed under ID '63f8a9089c6406e19244771d'                                  __main__.py:243\n",
        "DEBUG    Artifact size is 83.580 MB                                                           __main__.py:245\n",
        "INFO     Finished üöÄ                                                                          __main__.py:246\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l4e4GrspilM"
      },
      "source": [
        "## Saving\n",
        "\n",
        "After the run has finished successfully, you can download the tuned model on your local machine:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzfxhqeCmCa8"
      },
      "outputs": [],
      "source": [
        "artifact = run.save_artifact('resnet-model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkNHTyBkprQ0"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Now you saved the `artifact` into your host machine,\n",
        "let's use the fine-tuned model to encode a new `Document`:\n",
        "\n",
        "```{admonition} Inference with ONNX\n",
        "In case you set `to_onnx=True` when calling `finetuner.fit` function,\n",
        "please use `model = finetuner.get_model(artifact, is_onnx=True)`\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOi5qcNLplaI"
      },
      "outputs": [],
      "source": [
        "query = DocumentArray([query_data[0]])\n",
        "\n",
        "model = finetuner.get_model(artifact=artifact, device='cuda')\n",
        "\n",
        "finetuner.encode(model=model, data=query)\n",
        "finetuner.encode(model=model, data=index_data)\n",
        "\n",
        "assert query.embeddings.shape == (1, 2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cC46TQ9pw-H"
      },
      "source": [
        "And finally, you can use the embedded `query` to find top-k visually related images within `index_data` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYMnyr6ac4ln"
      },
      "outputs": [],
      "source": [
        "query.match(index_data, limit=10, metric='cosine')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "irvn0igWdLOf"
      },
      "source": [
        "## Before and after\n",
        "We can directly compare the results of our fine-tuned model with its zero-shot counterpart to get a better idea of how fine-tuning affects the results of a search. Each class of the Stanford cars dataset contains images for a single model of car. Therefore, we can define a 'good' search result as an image of a car that is the same model as the car in the query image, and not necessarily images of cars that are taken at a similar angle, or are the same colour.  \n",
        "The example below shows exactly this:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TwL33Jz1datD"
      },
      "source": [
        "query                      |before             |  after\n",
        ":-------------------------:|:-------------------------:|:-------------------------:\n",
        "![cars-query](https://user-images.githubusercontent.com/58855099/221186269-a7ebbcd0-6865-45ea-b539-9756d87b3853.png) | ![cars-result-zs](https://user-images.githubusercontent.com/58855099/221186221-6d5bfb9b-2a44-4436-a1af-4c6763eb3b5b.png)  |  ![cars-result-ft](https://user-images.githubusercontent.com/58855099/221187091-adf30d01-9773-4fa6-8e32-b2f45916ff55.png)\n",
        "![cars-query](https://user-images.githubusercontent.com/58855099/221221384-28734a84-b00a-4605-bfca-28579462ab95.png) | ![cars-result-zs](https://user-images.githubusercontent.com/58855099/221222634-09caec10-6c21-4fba-a098-d9421436d182.png)  |  ![cars-result-ft](https://user-images.githubusercontent.com/58855099/221221342-8a6b1263-f3dd-43d9-bc1f-aa1a7d0cc728.png)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "3db2bdf41d9da34160d1d34e7a6d535d86d0a181bbae01d6e8b2a2eb77f9aef9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
