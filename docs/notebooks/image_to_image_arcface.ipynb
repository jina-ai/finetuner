{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p8jc8EyfruKw"
      },
      "source": [
        "# Image-to-Image Search with ArcFaceLoss\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1ZS9FmnR9FzO_JYGCPazFM7TcMNQl51xM?usp=sharing\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n",
        "\n",
        "Searching visually similar images with image queries is a very popular use case. However, using pre-trained models does not deliver the best results ‚Äì the models are trained on general data that lack the particularities of your specific task. Here's where Finetuner comes in! It enables you to accomplish this easily.\n",
        "\n",
        "This guide will demonstrate how to fine-tune a ResNet model using the `ArcFaceLoss` function.\n",
        "\n",
        "*Note, please consider switching to GPU/TPU Runtime for faster inference.*\n",
        "\n",
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdKH0S0FrwS3"
      },
      "outputs": [],
      "source": [
        "!pip install 'finetuner[full]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EliQdGCsdL0"
      },
      "source": [
        "## Task\n",
        "\n",
        "More specifically, we will fine-tune ResNet50 on [Stanford Cars Dataset](http://ai.stanford.edu/~jkrause/cars/car_dataset.html).\n",
        "This dataset consists of 196 classes across 16184 docuemnts in total.\n",
        "\n",
        "Each class of the dataset consists of roughly 82 documents, in order to group the documents of each class together and move separate documents of different classes apart, we use the `ArcFaceLoss` function. For more information on how this loss function works, see [Advanced Losses and Optimizers](https://finetuner.jina.ai/advanced-topics/advanced-losses-and-optimizers/)\n",
        "\n",
        "After fine-tuning, documents from each class should have similar embeddings, distinct from documents of other classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1sii3xdtD2y"
      },
      "source": [
        "## Data\n",
        "\n",
        "Our journey starts locally. We have to prepare the data and push it to the Jina AI Cloud and Finetuner will be able to get the dataset by its name. For this example,\n",
        "we already prepared the data, and we'll provide the names of training data (`stanford-cars-train`) directly to Finetuner.\n",
        "\n",
        "```{important} \n",
        "We don't require you to push data to the Jina AI Cloud by yourself. Instead of a name, you can provide a `DocumentArray` and Finetuner will do the job for you.\n",
        "When working with documents where images are stored locally, please call `doc.load_uri_to_blob()` to reduce network transmission and speed up training.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0NfPGbTkNsc"
      },
      "outputs": [],
      "source": [
        "import finetuner\n",
        "from docarray import DocumentArray, Document\n",
        "\n",
        "finetuner.login(force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONpXDwFBsqQS"
      },
      "outputs": [],
      "source": [
        "train_data = DocumentArray.pull('finetuner/stanford-cars-train', show_progress=True)\n",
        "query_data = DocumentArray.pull('finetuner/stanford-cars-query', show_progress=True)\n",
        "index_data = DocumentArray.pull('finetuner/stanford-cars-index', show_progress=True)\n",
        "\n",
        "train_data.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUoY1jq0klwk"
      },
      "source": [
        "## Backbone model\n",
        "Now let's see which backbone models we can use. You can see available models by calling `finetuner.describe_models()`.\n",
        "\n",
        "\n",
        "For this example, we're gonna go with `resnet50`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA7IIhIOk0h0"
      },
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Now that we have the training and evaluation datasets loaded as `DocumentArray`s and selected our model, we can start our fine-tuning run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGrHfz-2kVC7"
      },
      "outputs": [],
      "source": [
        "from finetuner.callback import EvaluationCallback\n",
        "\n",
        "run = finetuner.fit(\n",
        "    model='resnet50',\n",
        "    train_data='finetuner/stanford-cars-train',\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    learning_rate=1e-3,\n",
        "    loss='ArcFaceLoss',\n",
        "    device='cuda',\n",
        "    sampler='random',\n",
        "    callbacks=[\n",
        "        EvaluationCallback(\n",
        "            query_data='finetuner/stanford-cars-query',\n",
        "            index_data='finetuner/stanford-cars-index',\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvoWipMlG5P"
      },
      "source": [
        "Let's understand what this piece of code does:\n",
        "\n",
        "* As you can see, we have to provide the `model` which we picked before.\n",
        "* We also set `run_name` and `description`, which are optional,\n",
        "but recommended in order to retrieve your run easily and have some context about it.\n",
        "* Furthermore, we had to provide names of the `train_data`.\n",
        "* We set `ArcFaceLoss`.\n",
        "* Additionally, we use `finetuner.callback.EvaluationCallback` for evaluation.\n",
        "* Lastly, we set the number of `epochs` and provide a `learning_rate`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ftSOH_olcak"
      },
      "source": [
        "## Monitoring\n",
        "\n",
        "Now that we've created a run, let's see its status. You can monitor the run by checking the status - `run.status()` - and the logs - `run.logs()` or `run.stream_logs()`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k3hTskflI7e"
      },
      "outputs": [],
      "source": [
        "# note, the fine-tuning might takes 30~ minutes\n",
        "for entry in run.stream_logs():\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8O-Ms_El-lV"
      },
      "source": [
        "Since some runs might take up to several hours, it's important to know how to reconnect to Finetuner and retrieve your runs.\n",
        "\n",
        "```python\n",
        "import finetuner\n",
        "finetuner.login()\n",
        "\n",
        "run = finetuner.get_run(run.name)\n",
        "```\n",
        "\n",
        "You can continue monitoring the runs by checking the status - `finetuner.run.Run.status()` or the logs - `finetuner.run.Run.logs()`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMpQxydypeZ3"
      },
      "source": [
        "## Evaluating\n",
        "Currently, we don't have a user-friendly way to get evaluation metrics from the `finetuner.callback.EvaluationCallback` we initialized previously.\n",
        "What you can do for now is to call `run.logs()` after the end of the run and see the evaluation results:\n",
        "\n",
        "```bash\n",
        "Training [5/5] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 48/48 0:00:00 0:00:12 ‚Ä¢ loss: 13.986\n",
        "INFO     Done ‚ú®                                                                              __main__.py:195\n",
        "DEBUG    Finetuning took 0 days, 0 hours 3 minutes and 48 seconds                             __main__.py:197\n",
        "INFO     Metric: 'resnet50_precision_at_k' before fine-tuning:  0.11575 after fine-tuning:    __main__.py:210\n",
        "0.53425\n",
        "INFO     Metric: 'resnet50_recall_at_k' before fine-tuning:  0.05745 after fine-tuning:       __main__.py:210\n",
        "0.27113\n",
        "INFO     Metric: 'resnet50_f1_score_at_k' before fine-tuning:  0.07631 after fine-tuning:     __main__.py:210\n",
        "0.35788\n",
        "INFO     Metric: 'resnet50_hit_at_k' before fine-tuning:  0.82900 after fine-tuning: 0.94100  __main__.py:210\n",
        "INFO     Metric: 'resnet50_average_precision' before fine-tuning:  0.52305 after fine-tuning: __main__.py:210\n",
        "0.79779\n",
        "INFO     Metric: 'resnet50_reciprocal_rank' before fine-tuning:  0.64909 after fine-tuning:   __main__.py:210\n",
        "0.89224\n",
        "INFO     Metric: 'resnet50_dcg_at_k' before fine-tuning:  1.30710 after fine-tuning: 4.52143  __main__.py:210\n",
        "INFO     Building the artifact ...                                                            __main__.py:215\n",
        "INFO     Pushing artifact to Jina AI Cloud ...                                                __main__.py:241\n",
        "[12:19:53] INFO     Artifact pushed under ID '63f8a9089c6406e19244771d'                                  __main__.py:243\n",
        "DEBUG    Artifact size is 83.580 MB                                                           __main__.py:245\n",
        "INFO     Finished üöÄ                                                                          __main__.py:246\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l4e4GrspilM"
      },
      "source": [
        "## Saving\n",
        "\n",
        "After the run has finished successfully, you can download the tuned model on your local machine:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzfxhqeCmCa8"
      },
      "outputs": [],
      "source": [
        "artifact = run.save_artifact('resnet-model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkNHTyBkprQ0"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Now you saved the `artifact` into your host machine,\n",
        "let's use the fine-tuned model to encode a new `Document`:\n",
        "\n",
        "```{admonition} Inference with ONNX\n",
        "In case you set `to_onnx=True` when calling `finetuner.fit` function,\n",
        "please use `model = finetuner.get_model(artifact, is_onnx=True)`\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOi5qcNLplaI"
      },
      "outputs": [],
      "source": [
        "query = DocumentArray([query_data[0]])\n",
        "\n",
        "model = finetuner.get_model(artifact=artifact, device='cuda')\n",
        "\n",
        "finetuner.encode(model=model, data=query)\n",
        "finetuner.encode(model=model, data=index_data)\n",
        "\n",
        "assert query.embeddings.shape == (1, 2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cC46TQ9pw-H"
      },
      "source": [
        "And finally, you can use the embedded `query` to find top-k visually related images within `index_data` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYMnyr6ac4ln"
      },
      "outputs": [],
      "source": [
        "query.match(index_data, limit=10, metric='cosine')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irvn0igWdLOf"
      },
      "source": [
        "## Before and after\n",
        "We can directly compare the results of our fine-tuned model with its zero-shot counterpart to get a better idea of how finetuning affects the results of a search. Each class of the Stanford cars dataset contains images for a single model of car. Therefore, we would expect the search results after finetuning to return more images of cars that are of the same model as the car in the query image. The improvement in results can be quite subtle for some queries, though the example below clearly shows that fine-tuning increases the quality of the search results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwL33Jz1datD"
      },
      "source": [
        "query                      |before             |  after\n",
        ":-------------------------:|:-------------------------:|:-------------------------:\n",
        "![cars-query](https://user-images.githubusercontent.com/58855099/221186269-a7ebbcd0-6865-45ea-b539-9756d87b3853.png) | ![cars-result-zs](https://user-images.githubusercontent.com/58855099/221186221-6d5bfb9b-2a44-4436-a1af-4c6763eb3b5b.png)  |  ![cars-result-ft](https://user-images.githubusercontent.com/58855099/221187091-adf30d01-9773-4fa6-8e32-b2f45916ff55.png)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "3db2bdf41d9da34160d1d34e7a6d535d86d0a181bbae01d6e8b2a2eb77f9aef9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
