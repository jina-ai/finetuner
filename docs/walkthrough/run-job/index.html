<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Run Job" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://finetuner.jina.ai/walkthrough/run-job/" />
<meta property="og:site_name" content="Finetuner Documentation" />
<meta property="og:description" content="Now you should have your training data and evaluation data (optional) prepared as CSV files or DocumentArray s, and have selected your backbone model. Up until now, you have worked locally to prepare a dataset and select our model. From here on out, you will send your processes to the cloud! Subm..." />
<meta property="og:image" content="https://user-images.githubusercontent.com/6599259/221238105-ee294b7e-544a-4de8-8c92-0c61275f29bb.png" />
<meta property="og:image:alt" content="Learning Rate" />
<meta name="description" content="Now you should have your training data and evaluation data (optional) prepared as CSV files or DocumentArray s, and have selected your backbone model. Up until now, you have worked locally to prepare a dataset and select our model. From here on out, you will send your processes to the cloud! Subm..." />
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@JinaAI_">
<meta name="twitter:creator" content="@JinaAI_">
<meta name="description" content="Finetuner is a library for tune the weights of any deep neural network for better embeddings on search tasks.">
<meta property="og:description" content="Finetuner allows one to tune the weights of any deep neural network for better embeddings on search tasks. It accompanies Jina to deliver the last mile of performance for domain-specific neural search applications.">

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1ESRNDCK35"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1ESRNDCK35');
</script>

<script async defer src="https://buttons.github.io/buttons.js"></script>
    
<link rel="index" title="Index" href="../../genindex/" /><link rel="search" title="Search" href="../../search/" /><link rel="next" title="Save Artifact" href="../save-model/" /><link rel="prev" title="Backbone Model" href="../choose-backbone/" />
        <link rel="canonical" href="https://finetuner.jina.ai/walkthrough/run-job.html" />

    <link rel="shortcut icon" href="../../_static/favicon.png"/><!-- Generated with Sphinx 7.0.1 and Furo 2023.05.20 -->
        <title>Run Job - Finetuner documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=e6660623a769aa55fea372102b9bf3151b292993" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../../_static/main.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: #4d4d4d;
  --color-brand-primary: #009191;
  --color-brand-content: #009191;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
    <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
    <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
    <header class="mobile-header">
        <div class="header-left">
            <label class="nav-overlay-icon" for="__navigation">
                <div class="visually-hidden">Toggle site navigation sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-menu"></use>
                    </svg>
                </i>
            </label>
        </div>
        <div class="header-center">
            <a href="../../">
                <div class="brand">Finetuner  documentation</div>
            </a>
        </div>
        <div class="header-right">
            <div class="theme-toggle-container theme-toggle-header">
                <button class="theme-toggle">
                    <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                    <svg class="theme-icon-when-auto">
                        <use href="#svg-sun-half"></use>
                    </svg>
                    <svg class="theme-icon-when-dark">
                        <use href="#svg-moon"></use>
                    </svg>
                    <svg class="theme-icon-when-light">
                        <use href="#svg-sun"></use>
                    </svg>
                </button>
            </div>
            <label class="toc-overlay-icon toc-header-icon" for="__toc">
                <div class="visually-hidden">Toggle table of contents sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-toc"></use>
                    </svg>
                </i>
            </label>
        </div>
    </header>
    <aside class="sidebar-drawer">
        <div class="sidebar-container">
            
            <div class="sidebar-sticky"><a class="sidebar-brand" href="../../">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/logo-light.svg" alt="Light Logo" />
    <img class="sidebar-logo only-dark" src="../../_static/logo-dark.svg" alt="Dark Logo" />
  </div>
  
  
</a>
<div class="sd-d-flex-row sd-align-major-spaced">
  <a class="github-button" href="https://github.com/jina-ai/finetuner" data-icon="octicon-star" data-show-count="true" aria-label="Star jina-ai/jina on GitHub" style="opacity: 0;">Star</a>
  
</div><form class="sidebar-search-container" method="get" action="../../search/" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
    <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../get-started/how-it-works/"><svg aria-hidden="true" class="sd-octicon sd-octicon-question" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm9 3a1 1 0 11-2 0 1 1 0 012 0zM6.92 6.085c.081-.16.19-.299.34-.398.145-.097.371-.187.74-.187.28 0 .553.087.738.225A.613.613 0 019 6.25c0 .177-.04.264-.077.318a.956.956 0 01-.277.245c-.076.051-.158.1-.258.161l-.007.004a7.728 7.728 0 00-.313.195 2.416 2.416 0 00-.692.661.75.75 0 001.248.832.956.956 0 01.276-.245 6.3 6.3 0 01.26-.16l.006-.004c.093-.057.204-.123.313-.195.222-.149.487-.355.692-.662.214-.32.329-.702.329-1.15 0-.76-.36-1.348-.863-1.725A2.76 2.76 0 008 4c-.631 0-1.155.16-1.572.438-.413.276-.68.638-.849.977a.75.75 0 101.342.67z" fill-rule="evenodd"></path></svg> How Does it Work?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get-started/installation/"><svg aria-hidden="true" class="sd-octicon sd-octicon-desktop-download" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M4.927 5.427l2.896 2.896a.25.25 0 00.354 0l2.896-2.896A.25.25 0 0010.896 5H8.75V.75a.75.75 0 10-1.5 0V5H5.104a.25.25 0 00-.177.427z"></path><path d="M1.573 2.573a.25.25 0 00-.073.177v7.5a.25.25 0 00.25.25h12.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-3a.75.75 0 110-1.5h3A1.75 1.75 0 0116 2.75v7.5A1.75 1.75 0 0114.25 12h-3.727c.099 1.041.52 1.872 1.292 2.757A.75.75 0 0111.25 16h-6.5a.75.75 0 01-.565-1.243c.772-.885 1.192-1.716 1.292-2.757H1.75A1.75 1.75 0 010 10.25v-7.5A1.75 1.75 0 011.75 1h3a.75.75 0 010 1.5h-3a.25.25 0 00-.177.073zM6.982 12a5.72 5.72 0 01-.765 2.5h3.566a5.72 5.72 0 01-.765-2.5H6.982z"></path></svg> Installation</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../"><svg aria-hidden="true" class="sd-octicon sd-octicon-list-ordered" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M2.003 2.5a.5.5 0 00-.723-.447l-1.003.5a.5.5 0 00.446.895l.28-.14V6H.5a.5.5 0 000 1h2.006a.5.5 0 100-1h-.503V2.5zM5 3.25a.75.75 0 01.75-.75h8.5a.75.75 0 010 1.5h-8.5A.75.75 0 015 3.25zm0 5a.75.75 0 01.75-.75h8.5a.75.75 0 010 1.5h-8.5A.75.75 0 015 8.25zm0 5a.75.75 0 01.75-.75h8.5a.75.75 0 010 1.5h-8.5a.75.75 0 01-.75-.75zM.924 10.32l.003-.004a.851.851 0 01.144-.153A.66.66 0 011.5 10c.195 0 .306.068.374.146a.57.57 0 01.128.376c0 .453-.269.682-.8 1.078l-.035.025C.692 11.98 0 12.495 0 13.5a.5.5 0 00.5.5h2.003a.5.5 0 000-1H1.146c.132-.197.351-.372.654-.597l.047-.035c.47-.35 1.156-.858 1.156-1.845 0-.365-.118-.744-.377-1.038-.268-.303-.658-.484-1.126-.484-.48 0-.84.202-1.068.392a1.858 1.858 0 00-.348.384l-.007.011-.002.004-.001.002-.001.001a.5.5 0 00.851.525zM.5 10.055l-.427-.26.427.26z" fill-rule="evenodd"></path></svg> Walkthrough</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of  Walkthrough</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../basic-concepts/">Basic Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../login/">Login</a></li>
<li class="toctree-l2"><a class="reference internal" href="../create-training-data/">Prepare Training Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../choose-backbone/">Backbone Model</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Run Job</a></li>
<li class="toctree-l2"><a class="reference internal" href="../save-model/">Save Artifact</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inference/">Inference</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/budget/"><svg aria-hidden="true" class="sd-octicon sd-octicon-database" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M2.5 3.5c0-.133.058-.318.282-.55.227-.237.592-.484 1.1-.708C4.899 1.795 6.354 1.5 8 1.5c1.647 0 3.102.295 4.117.742.51.224.874.47 1.101.707.224.233.282.418.282.551 0 .133-.058.318-.282.55-.227.237-.592.484-1.1.708C11.101 5.205 9.646 5.5 8 5.5c-1.647 0-3.102-.295-4.117-.742-.51-.224-.874-.47-1.101-.707-.224-.233-.282-.418-.282-.551zM1 3.5c0-.626.292-1.165.7-1.59.406-.422.956-.767 1.579-1.041C4.525.32 6.195 0 8 0c1.805 0 3.475.32 4.722.869.622.274 1.172.62 1.578 1.04.408.426.7.965.7 1.591v9c0 .626-.292 1.165-.7 1.59-.406.422-.956.767-1.579 1.041C11.476 15.68 9.806 16 8 16c-1.805 0-3.475-.32-4.721-.869-.623-.274-1.173-.62-1.579-1.04-.408-.426-.7-.965-.7-1.591v-9zM2.5 8V5.724c.241.15.503.286.779.407C4.525 6.68 6.195 7 8 7c1.805 0 3.475-.32 4.722-.869.275-.121.537-.257.778-.407V8c0 .133-.058.318-.282.55-.227.237-.592.484-1.1.708C11.101 9.705 9.646 10 8 10c-1.647 0-3.102-.295-4.117-.742-.51-.224-.874-.47-1.101-.707C2.558 8.318 2.5 8.133 2.5 8zm0 2.225V12.5c0 .133.058.318.282.55.227.237.592.484 1.1.708 1.016.447 2.471.742 4.118.742 1.647 0 3.102-.295 4.117-.742.51-.224.874-.47 1.101-.707.224-.233.282-.418.282-.551v-2.275c-.241.15-.503.285-.778.406-1.247.549-2.917.869-4.722.869-1.805 0-3.475-.32-4.721-.869a6.236 6.236 0 01-.779-.406z" fill-rule="evenodd"></path></svg> How much data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/negative-mining/"><svg aria-hidden="true" class="sd-octicon sd-octicon-telescope" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M14.184 1.143a1.75 1.75 0 00-2.502-.57L.912 7.916a1.75 1.75 0 00-.53 2.32l.447.775a1.75 1.75 0 002.275.702l11.745-5.656a1.75 1.75 0 00.757-2.451l-1.422-2.464zm-1.657.669a.25.25 0 01.358.081l1.422 2.464a.25.25 0 01-.108.35l-2.016.97-1.505-2.605 1.85-1.26zM9.436 3.92l1.391 2.41-5.42 2.61-.942-1.63 4.97-3.39zM3.222 8.157l-1.466 1a.25.25 0 00-.075.33l.447.775a.25.25 0 00.325.1l1.598-.769-.83-1.436zm6.253 2.306a.75.75 0 00-.944-.252l-1.809.87a.75.75 0 00-.293.253L4.38 14.326a.75.75 0 101.238.848l1.881-2.75v2.826a.75.75 0 001.5 0v-2.826l1.881 2.75a.75.75 0 001.238-.848l-2.644-3.863z" fill-rule="evenodd"></path></svg> Negative Mining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/using-callbacks/"><svg aria-hidden="true" class="sd-octicon sd-octicon-link" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z" fill-rule="evenodd"></path></svg> Using Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/linear-probe/"><svg aria-hidden="true" class="sd-octicon sd-octicon-pin" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M4.456.734a1.75 1.75 0 012.826.504l.613 1.327a3.081 3.081 0 002.084 1.707l2.454.584c1.332.317 1.8 1.972.832 2.94L11.06 10l3.72 3.72a.75.75 0 11-1.061 1.06L10 11.06l-2.204 2.205c-.968.968-2.623.5-2.94-.832l-.584-2.454a3.081 3.081 0 00-1.707-2.084l-1.327-.613a1.75 1.75 0 01-.504-2.826L4.456.734zM5.92 1.866a.25.25 0 00-.404-.072L1.794 5.516a.25.25 0 00.072.404l1.328.613A4.582 4.582 0 015.73 9.63l.584 2.454a.25.25 0 00.42.12l5.47-5.47a.25.25 0 00-.12-.42L9.63 5.73a4.581 4.581 0 01-3.098-2.537L5.92 1.866z" fill-rule="evenodd"></path></svg> Projection Head</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/advanced-losses-optimizers-and-poolers/"><svg aria-hidden="true" class="sd-octicon sd-octicon-mortar-board" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M7.693 1.066a.75.75 0 01.614 0l7.25 3.25a.75.75 0 010 1.368L13 6.831v2.794c0 1.024-.81 1.749-1.66 2.173-.893.447-2.075.702-3.34.702-.278 0-.55-.012-.816-.036a.75.75 0 01.133-1.494c.22.02.45.03.683.03 1.082 0 2.025-.221 2.67-.543.69-.345.83-.682.83-.832V7.503L8.307 8.934a.75.75 0 01-.614 0L4 7.28v1.663c.296.105.575.275.812.512.438.438.688 1.059.688 1.796v3a.75.75 0 01-.75.75h-3a.75.75 0 01-.75-.75v-3c0-.737.25-1.358.688-1.796.237-.237.516-.407.812-.512V6.606L.443 5.684a.75.75 0 010-1.368l7.25-3.25zM2.583 5L8 7.428 13.416 5 8 2.572 2.583 5zM2.5 11.25c0-.388.125-.611.25-.735a.704.704 0 01.5-.203c.19 0 .37.071.5.203.125.124.25.347.25.735v2.25H2.5v-2.25z" fill-rule="evenodd"></path></svg> Advanced loss functions, optimizers and poolers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-topics/finetuner-executor/"><svg aria-hidden="true" class="sd-octicon sd-octicon-gear" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M7.429 1.525a6.593 6.593 0 011.142 0c.036.003.108.036.137.146l.289 1.105c.147.56.55.967.997 1.189.174.086.341.183.501.29.417.278.97.423 1.53.27l1.102-.303c.11-.03.175.016.195.046.219.31.41.641.573.989.014.031.022.11-.059.19l-.815.806c-.411.406-.562.957-.53 1.456a4.588 4.588 0 010 .582c-.032.499.119 1.05.53 1.456l.815.806c.08.08.073.159.059.19a6.494 6.494 0 01-.573.99c-.02.029-.086.074-.195.045l-1.103-.303c-.559-.153-1.112-.008-1.529.27-.16.107-.327.204-.5.29-.449.222-.851.628-.998 1.189l-.289 1.105c-.029.11-.101.143-.137.146a6.613 6.613 0 01-1.142 0c-.036-.003-.108-.037-.137-.146l-.289-1.105c-.147-.56-.55-.967-.997-1.189a4.502 4.502 0 01-.501-.29c-.417-.278-.97-.423-1.53-.27l-1.102.303c-.11.03-.175-.016-.195-.046a6.492 6.492 0 01-.573-.989c-.014-.031-.022-.11.059-.19l.815-.806c.411-.406.562-.957.53-1.456a4.587 4.587 0 010-.582c.032-.499-.119-1.05-.53-1.456l-.815-.806c-.08-.08-.073-.159-.059-.19a6.44 6.44 0 01.573-.99c.02-.029.086-.075.195-.045l1.103.303c.559.153 1.112.008 1.529-.27.16-.107.327-.204.5-.29.449-.222.851-.628.998-1.189l.289-1.105c.029-.11.101-.143.137-.146zM8 0c-.236 0-.47.01-.701.03-.743.065-1.29.615-1.458 1.261l-.29 1.106c-.017.066-.078.158-.211.224a5.994 5.994 0 00-.668.386c-.123.082-.233.09-.3.071L3.27 2.776c-.644-.177-1.392.02-1.82.63a7.977 7.977 0 00-.704 1.217c-.315.675-.111 1.422.363 1.891l.815.806c.05.048.098.147.088.294a6.084 6.084 0 000 .772c.01.147-.038.246-.088.294l-.815.806c-.474.469-.678 1.216-.363 1.891.2.428.436.835.704 1.218.428.609 1.176.806 1.82.63l1.103-.303c.066-.019.176-.011.299.071.213.143.436.272.668.386.133.066.194.158.212.224l.289 1.106c.169.646.715 1.196 1.458 1.26a8.094 8.094 0 001.402 0c.743-.064 1.29-.614 1.458-1.26l.29-1.106c.017-.066.078-.158.211-.224a5.98 5.98 0 00.668-.386c.123-.082.233-.09.3-.071l1.102.302c.644.177 1.392-.02 1.82-.63.268-.382.505-.789.704-1.217.315-.675.111-1.422-.364-1.891l-.814-.806c-.05-.048-.098-.147-.088-.294a6.1 6.1 0 000-.772c-.01-.147.039-.246.088-.294l.814-.806c.475-.469.679-1.216.364-1.891a7.992 7.992 0 00-.704-1.218c-.428-.609-1.176-.806-1.82-.63l-1.103.303c-.066.019-.176.011-.299-.071a5.991 5.991 0 00-.668-.386c-.133-.066-.194-.158-.212-.224L10.16 1.29C9.99.645 9.444.095 8.701.031A8.094 8.094 0 008 0zm1.5 8a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0zM11 8a3 3 0 11-6 0 3 3 0 016 0z" fill-rule="evenodd"></path></svg> Use FinetunerExecutor inside a Jina Flow</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Finetuning Tasks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/text_to_text/">Text-to-Text Search via BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/image_to_image/">Image-to-Image Search with TripletMarginLoss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/image_to_image_arcface/">Image-to-Image Search with ArcFaceLoss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/text_to_image/">Text-to-Image Search via CLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/multilingual_text_to_image/">Multilingual Text-to-Image Search with MultilingualCLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/mesh_to_mesh/">3D Mesh-to-3D Mesh Search via PointNet++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/data_synthesis/">Data Synthesis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api-rst/"><span class="fab fa-python"></span> Python API</a></li>
</ul>

    <p class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul>
        <li class="toctree-l1">
            <a class="reference external" href="https://docs.jina.ai">
                <img class="sidebar-ecosys-logo only-light-line" src="../../_static/search-light.svg">
                <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/search-dark.svg">
                Jina</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://cloud.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/hub-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/hub-dark.svg">
            Jina Hub</a></li>
        <li class="toctree-l1"><a class="reference internal" href="#">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/finetuner-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/finetuner-dark.svg">
            Finetuner</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://docarray.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/docarray-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/docarray-dark.svg">
            DocArray</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://clip-as-service.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/cas-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/cas-dark.svg">
            CLIP-as-service</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://github.com/jina-ai/jcloud">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/JCloud-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/JCloud-dark.svg">
            JCloud</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://github.com/jina-ai/now">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/now-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/now-dark.svg">
            NOW</a></li>
    </ul>
</div>
</div>

            </div>
            
        </div>
    </aside>
    <div class="main">
        <div class="content">
            <div class="article-container">
                <a href="#" class="back-to-top muted-link">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
                    </svg>
                    <span>Back to top</span>
                </a>
                <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
                        <button class="theme-toggle">
                            <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                            <svg class="theme-icon-when-auto">
                                <use href="#svg-sun-half"></use>
                            </svg>
                            <svg class="theme-icon-when-dark">
                                <use href="#svg-moon"></use>
                            </svg>
                            <svg class="theme-icon-when-light">
                                <use href="#svg-sun"></use>
                            </svg>
                        </button>
                    </div>
                    <label class="toc-overlay-icon toc-content-icon"
                           for="__toc">
                        <div class="visually-hidden">Toggle table of contents sidebar</div>
                        <i class="icon">
                            <svg>
                                <use href="#svg-toc"></use>
                            </svg>
                        </i>
                    </label>
                </div>
                <article role="main">
                    <section class="tex2jax_ignore mathjax_ignore" id="run-job">
<span id="start-finetuner"></span><h1>Run Job<a class="headerlink" href="#run-job" title="Permalink to this heading">#</a></h1>
<p>Now you should have your training data and evaluation data (optional) prepared as CSV files or <a class="reference external" href="https://docarray.jina.ai/api/docarray.array.document/#docarray.array.document.DocumentArray" title="(in DocArray v0.21.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DocumentArray</span></code></a>s,
and have selected your backbone model.</p>
<p>Up until now, you have worked locally to prepare a dataset and select our model. From here on out, you will send your processes to the cloud!</p>
<section id="submit-a-finetuning-job-to-the-cloud">
<h2>Submit a Finetuning Job to the cloud<a class="headerlink" href="#submit-a-finetuning-job-to-the-cloud" title="Permalink to this heading">#</a></h2>
<p>To start fine-tuning, you can call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">finetuner</span>
<span class="kn">from</span> <span class="nn">finetuner</span> <span class="kn">import</span> <span class="n">DocumentArray</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="s1">&#39;path/to/some/data.csv&#39;</span>

<span class="n">run</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s1">&#39;efficientnet_b0&#39;</span><span class="p">,</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n">train_data</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Run name: </span><span class="si">{</span><span class="n">run</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Run status: </span><span class="si">{</span><span class="n">run</span><span class="o">.</span><span class="n">status</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Youâ€™ll see something like this in the terminal with a different run name:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Run<span class="w"> </span>name:<span class="w"> </span>vigilant-tereshkova
Run<span class="w"> </span>status:<span class="w"> </span>CREATED
</pre></div>
</div>
<p>During fine-tuning,
the run status changes from:</p>
<ol class="simple">
<li><p>CREATED: the <a class="reference internal" href="../../api/finetuner.run/#finetuner.run.Run" title="finetuner.run.Run"><code class="xref py py-class docutils literal notranslate"><span class="pre">Run</span></code></a> has been created and submitted to the job queue.</p></li>
<li><p>STARTED: the job is in progress</p></li>
<li><p>FINISHED: the job finished successfully, model has been sent to Jina AI Cloud.</p></li>
<li><p>FAILED: the job failed, please check the logs for more details.</p></li>
</ol>
</section>
<section id="continue-training-on-new-data">
<h2>Continue training on new data<a class="headerlink" href="#continue-training-on-new-data" title="Permalink to this heading">#</a></h2>
<p>Finetuner also supports continuing training a model produced by a previous fine-tuning run.
If you have additional data which you want to use to further train a model, you can do this by passing its artifact id to the fit function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="s1">&#39;path/to/another/data.csv&#39;</span>

<span class="n">run2</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s1">&#39;efficientnet_b0&#39;</span><span class="p">,</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
    <span class="n">model_artifact</span><span class="o">=</span><span class="n">run</span><span class="o">.</span><span class="n">artifact_id</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Run name: </span><span class="si">{</span><span class="n">run2</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Run status: </span><span class="si">{</span><span class="n">run2</span><span class="o">.</span><span class="n">status</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="hint admonition">
<p class="admonition-title">Continue training requires a model parameter </p>
<p>When you want to continue training, you still need to provide the <code class="docutils literal notranslate"><span class="pre">model</span></code> parameter
as well as the <code class="docutils literal notranslate"><span class="pre">model_artifact</span></code> parameter for Finetuner to correctly configure the new run.</p>
</div>
</section>
<section id="advanced-configurations">
<h2>Advanced configurations<a class="headerlink" href="#advanced-configurations" title="Permalink to this heading">#</a></h2>
<p>Beyond the simplest use case,
Finetuner gives you the flexibility to set hyper-parameters explicitly:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">finetuner</span>
<span class="kn">from</span> <span class="nn">finetuner</span> <span class="kn">import</span> <span class="n">DocumentArray</span>
<span class="kn">from</span> <span class="nn">finetuner.data</span> <span class="kn">import</span> <span class="n">CSVOptions</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="s1">&#39;path/to/some/train_data.csv&#39;</span>
<span class="n">eval_data</span> <span class="o">=</span> <span class="s1">&#39;path/to/some/eval_data.csv&#39;</span>

<span class="c1"># Create an experiment</span>
<span class="n">finetuner</span><span class="o">.</span><span class="n">create_experiment</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;finetune-flickr-dataset&#39;</span><span class="p">)</span>

<span class="n">run</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s1">&#39;efficientnet_b0&#39;</span><span class="p">,</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
    <span class="n">eval_data</span><span class="o">=</span><span class="n">eval_data</span><span class="p">,</span> 
    <span class="n">run_name</span><span class="o">=</span><span class="s1">&#39;finetune-flickr-dataset-efficientnet-1&#39;</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">&#39;this is a trial run on flickr8k dataset with efficientnet b0.&#39;</span><span class="p">,</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;finetune-flickr-dataset&#39;</span><span class="p">,</span> <span class="c1"># Link to the experiment created above.</span>
    <span class="n">model_options</span><span class="o">=</span><span class="p">{},</span> <span class="c1"># Additional options to pass to the model constructor.</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;TripletMarginLoss&#39;</span><span class="p">,</span> <span class="c1"># Use CLIPLoss for CLIP fine-tuning.</span>
    <span class="n">miner</span><span class="o">=</span><span class="s1">&#39;TripletMarginMiner&#39;</span><span class="p">,</span>
    <span class="n">miner_options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;margin&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">},</span> <span class="c1"># Additional options for the miner constructor.</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="c1"># Use a linear scheduler to adjust the learning rate.</span>
    <span class="n">scheduler_options</span><span class="o">=</span><span class="p">{},</span> <span class="c1"># Additional options for the scheduler.</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span>
    <span class="n">optimizer_options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span> <span class="c1"># Additional options for the optimizer.</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">scheduler_step</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span>
    <span class="n">freeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># If applied will freeze the embedding model, only train the MLP.</span>
    <span class="n">output_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="c1"># Attach a MLP on top of embedding model.</span>
    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">to_onnx</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># If set, please pass `is_onnx` when making inference.</span>
    <span class="n">csv_options</span><span class="o">=</span><span class="n">CSVOptions</span><span class="p">(),</span>  <span class="c1"># Additional options for reading data from a CSV file.</span>
    <span class="n">public</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># If set, anyone has the artifact id can download your fine-tuned model.</span>
    <span class="n">num_items_per_class</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>  <span class="c1"># How many items per class to include in a batch.</span>
<span class="p">)</span>
</pre></div>
</div>
<section id="loss-functions">
<h3>Loss functions<a class="headerlink" href="#loss-functions" title="Permalink to this heading">#</a></h3>
<p>The loss function determines the training objective.
The type of loss function which is most suitable for your task depends heavily on the task your training for.
For many retrieval tasks, the <code class="docutils literal notranslate"><span class="pre">TripletMarginLoss</span></code> is a good choice.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Please check the <a class="reference external" href="../../api/finetuner/#finetuner.fit">developer reference</a> to get the available options for <code class="docutils literal notranslate"><span class="pre">loss</span></code>, <code class="docutils literal notranslate"><span class="pre">miner</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer</span></code>, and <code class="docutils literal notranslate"><span class="pre">scheduler_step</span></code>.</p>
</div>
</section>
<section id="configuration-of-the-optimizer">
<h3>Configuration of the optimizer<a class="headerlink" href="#configuration-of-the-optimizer" title="Permalink to this heading">#</a></h3>
<p>Fintuner allows one to choose any of the optimizers provided by PyTorch.
By default, the <code class="docutils literal notranslate"><span class="pre">Adam</span></code> optimizer is selected.
To select a different one, you can specify its name in the <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> attribute of the fit function.
Possible values are: <code class="docutils literal notranslate"><span class="pre">Adadelta</span></code>, <code class="docutils literal notranslate"><span class="pre">Adagrad</span></code>, <code class="docutils literal notranslate"><span class="pre">Adam</span></code>, <code class="docutils literal notranslate"><span class="pre">AdamW</span></code>, <code class="docutils literal notranslate"><span class="pre">SparseAdam</span></code>, <code class="docutils literal notranslate"><span class="pre">Adamax</span></code>, <code class="docutils literal notranslate"><span class="pre">ASGD</span></code>, <code class="docutils literal notranslate"><span class="pre">LBFGS</span></code>, <code class="docutils literal notranslate"><span class="pre">NAdam</span></code>, <code class="docutils literal notranslate"><span class="pre">RAdam</span></code>, <code class="docutils literal notranslate"><span class="pre">RMSprop</span></code>, <code class="docutils literal notranslate"><span class="pre">Rprop</span></code>, and <code class="docutils literal notranslate"><span class="pre">SGD</span></code>.</p>
<p>Finetuner configures the learning rate of the optimizer by using the value of the <code class="docutils literal notranslate"><span class="pre">lr</span></code> option.
If you want to pass more parameters to the optimizer, you can specify them via <code class="docutils literal notranslate"><span class="pre">optimizer_options</span></code>.
For example, you can enable the weight decay of the Adam optimizer to penalize high weights in the model by setting <code class="docutils literal notranslate"><span class="pre">optimizer_options={'weight_decay':0.01}</span></code>.</p>
<p>For detailed documentation of the optimizers and their parameters, please take a look at the <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">PyTorch documentation</a>.</p>
<div class="hint admonition">
<p class="admonition-title">Choosing the right learning rate and number of epochs</p>
<p>The learning rate determines how strong the weights are adjusted after processing a batch of training data.
In general, you should choose a low learning rate (<code class="docutils literal notranslate"><span class="pre">1e-6</span></code> to <code class="docutils literal notranslate"><span class="pre">1e-4</span></code>) for fine-tuning.
Otherwise, it could happen, that your model overfits on the training data and forgets the knowledge learned during pre-training.
Similarly, two or three epochs (number of passes thorough the training data) are often enough for a fine-tuning job.</p>
</div>
</section>
<section id="configuration-of-a-learning-rate-scheduler">
<h3>Configuration of a learning rate scheduler<a class="headerlink" href="#configuration-of-a-learning-rate-scheduler" title="Permalink to this heading">#</a></h3>
<p>You can configure Finetuner to use a learning rate scheduler.
The scheduler is used to adjust the learning rate during training.
If no scheduler is configured, the learning rate is constant during training.
When a scheduler is configured, the learning rate is adjusted after each batch by default.
Alternatively, one can set <code class="docutils literal notranslate"><span class="pre">scheduler_optons</span> <span class="pre">=</span> <span class="pre">{'scheduler_step':</span> <span class="pre">'epoch'}</span></code> to adjust the learning rate after each epoch.
A scheduler usually has a warm-up phase, where the learning rate is increasing. After that most learning rate schedulers decrease the learning rate.
For example, the <code class="docutils literal notranslate"><span class="pre">linear</span></code> scheduler decreases the learning rate linearly from the initial learning rate:
<img alt="Learning Rate" src="https://user-images.githubusercontent.com/6599259/221238105-ee294b7e-544a-4de8-8c92-0c61275f29bb.png" />
The length of the warm-up phase is configured via the <code class="docutils literal notranslate"><span class="pre">num_warmup_steps</span></code> option inside <code class="docutils literal notranslate"><span class="pre">scheduler_optons</span></code>.
By default, it is set to zero.</p>
</section>
<section id="layer-wise-learning-rate-decay-llrd">
<h3>Layer-wise learning rate decay (LLRD)<a class="headerlink" href="#layer-wise-learning-rate-decay-llrd" title="Permalink to this heading">#</a></h3>
<p>The LLRD assigns different learning rates to each layer of the model backbone.
It sets a large learning rate for the top (last) layer and uses a multiplicative decay rate to decrease the learning rate layer-by-layer from top (last) to bottom (first).
With high learning rates,
the features recognized by the top layers change more and adapt to new tasks more easily,
while the bottom layers have low learning rates and more easily preserve the features learned during pre-training.</p>
<p>We recommended to use LLRD to fine-tune Transformers, such as Bert or CLIP.</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span>import finetuner

run = finetuner.fit(
<span class="w"> </span>   ...,
<span class="w"> </span>   optimizer=&#39;Adam&#39;
<span class="gi">+   optimizer_options={&#39;layer_wise_lr_decay&#39;: 0.98},</span>
<span class="w"> </span>   ...,
)
</pre></div>
</div>
</section>
<section id="construction-of-training-batches">
<h3>Construction of training batches<a class="headerlink" href="#construction-of-training-batches" title="Permalink to this heading">#</a></h3>
<p>The training of your model is done in batches.
The <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> parameter determines the number of items per batch.
Finetuner constructs batches so that each batch contains the same number of classes and
as many items per class as configured via the <code class="docutils literal notranslate"><span class="pre">num_items_per_class</span></code> parameter.
However, if it is not possible, e.g., because <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is not dividable by
<code class="docutils literal notranslate"><span class="pre">num_items_per_class</span></code> or the training dataset does not contain enough classes,
Finetuner tries to choose a similar value for <code class="docutils literal notranslate"><span class="pre">num_items_per_class</span></code> which is working.
A larger <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> results in faster training, though too large a <code class="docutils literal notranslate"><span class="pre">batch_</span> <span class="pre">size</span></code> can result
in out of memory errors. Typically, a <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> of 64 or 128 are good options when you
are unsure of how high you can set this value, however you can also choose to not set the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>
at all, in which case the highest possible value will be calculated for you automatically.</p>
</section>
</section>
</section>

                </article>
            </div>
            <footer>
                
                <div class="related-pages">
                    <a class="next-page" href="../save-model/">
                        <div class="page-info">
                            <div class="context">
                                <span>Next</span>
                            </div>
                            <div class="title">Save Artifact</div>
                        </div>
                        <svg class="furo-related-icon">
                            <use href="#svg-arrow-right"></use>
                        </svg>
                    </a>
                    <a class="prev-page" href="../choose-backbone/">
                        <svg class="furo-related-icon">
                            <use href="#svg-arrow-right"></use>
                        </svg>
                        <div class="page-info">
                            <div class="context">
                                <span>Previous</span>
                            </div>
                            
                            <div class="title">Backbone Model</div>
                            
                        </div>
                    </a>
                </div>
                <div class="bottom-of-page">
                    <div class="left-details">
                        <div class="copyright">
                            Copyright &#169; Jina AI Limited. All rights reserved.
                        </div><div class="last-updated">
                            Last updated on May 24, 2023</div>
                    </div>
                    <div class="right-details">
                        <div class="social-btns">
                            <a class='social-btn' href="https://github.com/jina-ai/finetuner/" aria-label="GitHub"
                               target="_blank" rel="noreferrer"> <i class="fab fa-github"></i></a>
                            <a class='social-btn' href="https://discord.jina.ai" aria-label="discord" target="_blank"
                               rel="noreferrer"> <i class="fab fa-discord"></i></a>
                            <a class='social-btn' href="https://youtube.com/c/jina-ai" aria-label="YouTube"
                               target="_blank" rel="noreferrer"> <i class="fab fa-youtube"></i></a>
                            <a class='social-btn' href="https://twitter.com/JinaAI_" aria-label="Twitter"
                               target="_blank" rel="noreferrer"> <i class="fab fa-twitter"></i></a>
                            <a class='social-btn' href="https://www.linkedin.com/company/jinaai/" aria-label="LinkedIn"
                               target="_blank" rel="noreferrer"> <i class="fab fa-linkedin"></i></a>
                        </div>
                    </div>
                </div>
                
            </footer>
        </div>
        <aside class="toc-drawer">
            
            
            <div class="toc-sticky toc-scroll">
                <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
                </div>
                <div class="toc-tree-container">
                    <div class="toc-tree">
                        <ul>
<li><a class="reference internal" href="#">Run Job</a><ul>
<li><a class="reference internal" href="#submit-a-finetuning-job-to-the-cloud">Submit a Finetuning Job to the cloud</a></li>
<li><a class="reference internal" href="#continue-training-on-new-data">Continue training on new data</a></li>
<li><a class="reference internal" href="#advanced-configurations">Advanced configurations</a><ul>
<li><a class="reference internal" href="#loss-functions">Loss functions</a></li>
<li><a class="reference internal" href="#configuration-of-the-optimizer">Configuration of the optimizer</a></li>
<li><a class="reference internal" href="#configuration-of-a-learning-rate-scheduler">Configuration of a learning rate scheduler</a></li>
<li><a class="reference internal" href="#layer-wise-learning-rate-decay-llrd">Layer-wise learning rate decay (LLRD)</a></li>
<li><a class="reference internal" href="#construction-of-training-batches">Construction of training batches</a></li>
</ul>
</li>
</ul>
</li>
</ul>

                    </div>
                </div>
            </div>
            
            
        </aside>

        <qa-bot
            token="vizI4XaM1li8kQW2kQOiiBjtk02hzBDl0Em8lBjpzAKsjhX_z03mix_i3wKpiA=="
            theme="infer"
            target="_self"
            orientation="bottom-right"
            title="Finetuner"
            description="Task-oriented finetuning for better embeddings on neural search"
            show-tip>
          <template>
            <dl>
             <dt>You can ask questions about our docs. Try:</dt>
             <dd>What is Finetuner?</dd>
             <dd>How does Finetuner Work?</dd>
             <dd>What makes Finetuner unique?</dd>
            </dl>
          </template>
          <template slot="texts">
            <span for="tip">Hi there ðŸ‘‹
         Ask our docs!</span>
            <span for="unknownAnswerText">ðŸ˜µâ€ðŸ’« I'm sorry but I don't know the answer.</span>
          </template>
        </qa-bot>
</div>
<img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=e0caedb8-a833-4e85-983d-d3394a5f16d2" /><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vue@2/dist/vue.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/qabot"></script>
    <script src="../../_static/source-in-links.js"></script>
    </body>
</html>